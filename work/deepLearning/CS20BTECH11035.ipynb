{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "id": "C-t8imOIPw87"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms import ToTensor\n",
        "import pickle\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#set precision of tensor output \n",
        "torch.set_printoptions(precision=10)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3pd1ofQthxDo"
      },
      "source": [
        "**LOADING IMAGES**\n",
        "\n",
        "<font size=2>unpickle function loads CIFAR10 datset into dictionary.\\\n",
        "File path stored in variable: file (line number 8) must be updated according to the system it is being runned in.\\\n",
        "image_list contains all CIFAR10 images loaded class wise.\\\n",
        "Images are loaded in 3X32X32(CXHXW) format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "id": "j-t5sWBMh-gF"
      },
      "outputs": [],
      "source": [
        "#function to load CIFAR10 data into a dictionary\n",
        "def unpickle(file):\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n",
        "\n",
        "#file path in local folder\n",
        "file='D:/sem6/deeplearning-AI5100/assignment2/cifar-10-python/cifar-10-batches-py/data_batch_1'\n",
        "dic=unpickle(file)\n",
        "\n",
        "#obtaining keys of dictionary and writing them in list\n",
        "key=list(dic.keys())\n",
        "\n",
        "#key[1] contains labels(class number) of images\n",
        "labels=dic[key[1]]\n",
        "#key[2] contains corresponding(to label) image data\n",
        "images=dic[key[2]]\n",
        "\n",
        "#image_list contains all images sorted class wise\n",
        "image_list=[[] for i in range(10)]\n",
        "for i,image in enumerate(images):\n",
        "    #convert np array(image) to tensor(float) and reshape it into shape(3,32,32)\n",
        "    tens=(torch.from_numpy(image).reshape(3,32,32)).type(torch.FloatTensor)\n",
        "    tens=tens/255\n",
        "    image_list[labels[i]].append(tens)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yDmBzYsjKSCj"
      },
      "source": [
        "**QUESTION 1:**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<Font size=2>**Activation Functions**\n",
        "\n",
        "sigmoid activation function(x)= e^x(1+e^x)\\\n",
        "relu activation function(x)=max(0,x)\\\n",
        "tanh activation function(x)=(e^x-e^(-x))/(e^x+e^(-x))\\\n",
        "parametric relu activation function(x)=max(0,x)+alpha*min(0,x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {
        "id": "STYQr8Y0OVE7"
      },
      "outputs": [],
      "source": [
        "#sigmoid activation function(x)= e^x(1+e^x)\n",
        "def sigmoid(x):\n",
        "  return torch.exp(x)/(1+torch.exp(x))\n",
        "\n",
        "#relu activation function(x)=max(0,x)\n",
        "def RELU(x):\n",
        "  return torch.maximum(torch.zeros(x.size()),x)\n",
        "\n",
        "#tanh activation function(x)=(e^x-e^(-x))/(e^x+e^(-x))\n",
        "def tanh(x):\n",
        "   return (torch.exp(x)-torch.exp(-x))/(torch.exp(x)+torch.exp(-x))\n",
        "  \n",
        "#parametric relu activation function(x)=max(0,x)+alpha*min(0,x).\n",
        "def parametric_RELU(x,alpha=0.01):\n",
        "    return torch.maximum(torch.zeros(x.size()),x)+alpha*torch.minimum(torch.zeros(x.size()),x)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<Font size=2>**Padding Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "id": "zTPYg75kastZ"
      },
      "outputs": [],
      "source": [
        "def padding_function(inp,padding):\n",
        "  #defining a zero tensor with required output shape\n",
        "  padded_tensor=torch.zeros([inp.shape[0],inp.shape[1]+2*padding[0],inp.shape[2]+2*padding[1]])\n",
        "\n",
        "  for i in range(padded_tensor.shape[0]):\n",
        "     padded_tensor[i,padding[0]:padded_tensor.shape[1]-padding[0],padding[1]:padded_tensor.shape[2]-padding[1]]=inp[i]\n",
        "     \n",
        "  return padded_tensor\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<Font size=2>**CONVOLUTION FUNCTION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {
        "id": "seC0VB7EP0di"
      },
      "outputs": [],
      "source": [
        "def convolution_function(input,kernel,stride=torch.tensor([1,1]),padding=torch.tensor([0,0]),func=sigmoid):\n",
        "  #applying padding to input\n",
        "  padded_inp=padding_function(input,padding)\n",
        "\n",
        "  #h,w are height and width of kernel\n",
        "  h=kernel.shape[1]\n",
        "  w=kernel.shape[2]\n",
        "\n",
        "  #H,W are height and width of input\n",
        "  H=padded_inp.shape[1]\n",
        "  W=padded_inp.shape[2]\n",
        "\n",
        "\n",
        "  #creating an output zero tensor with required size\n",
        "  output=torch.zeros([1,((H-h)//stride[0])+1,((W-w)//stride[1])+1])\n",
        "\n",
        "\n",
        "  i1=0\n",
        "  j1=0\n",
        "\n",
        "  #applying convolution\n",
        "  for i in range(0,H-h+1,stride[0]):\n",
        "    j1=0\n",
        "    for j in range(0,W-w+1,stride[1]):\n",
        "      output[0][i1][j1]=func(torch.mul(padded_inp[:,i:i+h,j:j+w],kernel).sum())\n",
        "      j1+=1\n",
        "    i1+=1\n",
        "\n",
        "\n",
        "  return output\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<Font size=2>**Printing outputs**\\\n",
        "prints input image,filter kernel and output activation map for different activation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGg7m1qQeEed",
        "outputId": "2b77e6bd-2058-473f-d338-e6ab75980adf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input image=\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "filter kernel= tensor([[[0.7431446314, 0.8424611688, 0.7571858168],\n",
            "         [0.3426302075, 0.4688355327, 0.1654633284],\n",
            "         [0.7201457620, 0.1477375627, 0.4922156930]],\n",
            "\n",
            "        [[0.5878730416, 0.7031455636, 0.8524572253],\n",
            "         [0.0880436301, 0.8709796071, 0.1328058243],\n",
            "         [0.7062750459, 0.8900207281, 0.7999311686]],\n",
            "\n",
            "        [[0.1097980738, 0.7082744241, 0.5206379890],\n",
            "         [0.9600731134, 0.4052015543, 0.8918163776],\n",
            "         [0.7783516645, 0.9596872330, 0.6908290982]]])\n",
            "SIGMOID output activation map= tensor([[[0.9960381389, 0.9997780323, 0.9997886419,  ..., 0.9997994900,\n",
            "          0.9997837543, 0.9971700311],\n",
            "         [0.9998899102, 0.9999982119, 0.9999983311,  ..., 0.9999984503,\n",
            "          0.9999982715, 0.9998662472],\n",
            "         [0.9999052882, 0.9999985695, 0.9999986887,  ..., 0.9999988079,\n",
            "          0.9999986291, 0.9998856187],\n",
            "         ...,\n",
            "         [0.9999080300, 0.9999975562, 0.9999915957,  ..., 0.9999998212,\n",
            "          0.9999998212, 0.9999739528],\n",
            "         [0.9999336600, 0.9999989271, 0.9999981523,  ..., 0.9999998212,\n",
            "          0.9999998212, 0.9999718070],\n",
            "         [0.9981135130, 0.9998303056, 0.9998110533,  ..., 0.9999290705,\n",
            "          0.9999325275, 0.9984347224]]])\n",
            "RELU output activation map= tensor([[[ 5.5270676613,  8.4127569199,  8.4618721008,  ...,\n",
            "           8.5144777298,  8.4388132095,  5.8646535873],\n",
            "         [ 9.1140108109, 13.2233533859, 13.3159179688,  ...,\n",
            "          13.3731346130, 13.2585372925,  8.9192037582],\n",
            "         [ 9.2647085190, 13.4455232620, 13.5488777161,  ...,\n",
            "          13.6385145187, 13.5026912689,  9.0760097504],\n",
            "         ...,\n",
            "         [ 9.2937927246, 12.9269590378, 11.6856899261,  ...,\n",
            "          15.5722455978, 15.6258487701, 10.5547142029],\n",
            "         [ 9.6209316254, 13.7279624939, 13.1931276321,  ...,\n",
            "          15.4321651459, 15.5173139572, 10.4756603241],\n",
            "         [ 6.2711462975,  8.6813182831,  8.5739221573,  ...,\n",
            "           9.5536422729,  9.6039648056,  6.4581236839]]])\n",
            "tanh output activation map= tensor([[[0.9999682903, 1.0000000000, 1.0000000000,  ..., 1.0000000000,\n",
            "          1.0000000000, 0.9999839067],\n",
            "         [1.0000000000, 1.0000000000, 1.0000000000,  ..., 1.0000000000,\n",
            "          1.0000000000, 1.0000000000],\n",
            "         [1.0000000000, 1.0000000000, 1.0000000000,  ..., 1.0000000000,\n",
            "          1.0000000000, 1.0000000000],\n",
            "         ...,\n",
            "         [1.0000000000, 1.0000000000, 1.0000000000,  ..., 1.0000000000,\n",
            "          1.0000000000, 1.0000000000],\n",
            "         [1.0000000000, 1.0000000000, 1.0000000000,  ..., 1.0000000000,\n",
            "          1.0000000000, 1.0000000000],\n",
            "         [0.9999928474, 1.0000000000, 1.0000000000,  ..., 1.0000000000,\n",
            "          1.0000000000, 0.9999950528]]])\n",
            "PARAMETRIC RELU output activation map= tensor([[[ 5.5270676613,  8.4127569199,  8.4618721008,  ...,\n",
            "           8.5144777298,  8.4388132095,  5.8646535873],\n",
            "         [ 9.1140108109, 13.2233533859, 13.3159179688,  ...,\n",
            "          13.3731346130, 13.2585372925,  8.9192037582],\n",
            "         [ 9.2647085190, 13.4455232620, 13.5488777161,  ...,\n",
            "          13.6385145187, 13.5026912689,  9.0760097504],\n",
            "         ...,\n",
            "         [ 9.2937927246, 12.9269590378, 11.6856899261,  ...,\n",
            "          15.5722455978, 15.6258487701, 10.5547142029],\n",
            "         [ 9.6209316254, 13.7279624939, 13.1931276321,  ...,\n",
            "          15.4321651459, 15.5173139572, 10.4756603241],\n",
            "         [ 6.2711462975,  8.6813182831,  8.5739221573,  ...,\n",
            "           9.5536422729,  9.6039648056,  6.4581236839]]])\n"
          ]
        }
      ],
      "source": [
        "#testing convolution function\n",
        "padding=torch.tensor([1,1])\n",
        "inp =  image_list[0][0]\n",
        "kernel=torch.rand([inp.shape[0],3,3])\n",
        "\n",
        "#printing input image\n",
        "print('input image=')\n",
        "plt.imshow(inp.permute(1,2,0))\n",
        "plt.show()\n",
        "\n",
        "#printing filter kernel\n",
        "print('filter kernel=',kernel)\n",
        "\n",
        "conv_output=convolution_function(input=inp,kernel=kernel,func=sigmoid)\n",
        "\n",
        "#print output activation map for different activation functions\n",
        "print('SIGMOID output activation map=',convolution_function(input=inp,padding=padding,kernel=kernel,func=sigmoid))\n",
        "print('RELU output activation map=',convolution_function(input=inp,padding=padding,kernel=kernel,func=RELU))\n",
        "print('tanh output activation map=',convolution_function(input=inp,padding=padding,kernel=kernel,func=tanh))\n",
        "print('PARAMETRIC RELU output activation map=',convolution_function(input=inp,padding=padding,kernel=kernel,func=parametric_RELU))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mvwpSZUXjKX3"
      },
      "source": [
        "**QUESTION 2**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<font size=2>**Avg pooling function:**\n",
        "(sum of all elements in matrix)/(number of elements in matrix)\\\n",
        "**Max pooling function:**\n",
        "max(elements in matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {
        "id": "VW-q4OGioVcD"
      },
      "outputs": [],
      "source": [
        "#average pooling function\n",
        "def avg_pool(tens):\n",
        "  return tens.sum()/(tens.shape[0]*tens.shape[1])\n",
        "\n",
        "#max pooling function\n",
        "def max_pool(tens):\n",
        "  return torch.max(tens)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<Font size=2> **POOLING FUNCTION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "id": "JVhHUZ4-jUOO"
      },
      "outputs": [],
      "source": [
        "def pooling_function(inp,stride,pooling_func,kernel_size=None):\n",
        "  if kernel_size==None:\n",
        "    kernel_size=torch.tensor([stride[0],stride[1]])\n",
        "  #h,w are height and width of kernel\n",
        "  h=kernel_size[0]\n",
        "  w=kernel_size[1]\n",
        "\n",
        "  #H,W are height and width of input\n",
        "  H=inp.shape[1]\n",
        "  W=inp.shape[2]\n",
        "\n",
        "  #creating an output zero tensor with required size\n",
        "  output=torch.zeros([1,((H-h)//h)+1,((W-w)//w)+1])\n",
        " \n",
        "  i1=0\n",
        "  j1=0\n",
        "\n",
        "  #pooling function\n",
        "  for i in range(0,H-h+1,stride[0]):\n",
        "    j1=0\n",
        "    for j in range(0,W-w+1,stride[1]):\n",
        "        output[0][i1][j1]=pooling_func(inp[0,i:i+h,j:j+w])\n",
        "        j1+=1\n",
        "    i1+=1\n",
        "    \n",
        "  return output\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<Font size=2>**Printing outputs**\\\n",
        "prints input activation map,pooled output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_dkbVjppcw9",
        "outputId": "d8746817-f405-45b8-b527-d76f86b2b023"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input activation map= tensor([[[0.9999982119, 0.9999983311, 0.9999985099, 0.9999986887, 0.9999988079,\n",
            "          0.9999989271, 0.9999989867, 0.9999991059, 0.9999991655, 0.9999992251,\n",
            "          0.9999992251, 0.9999992847, 0.9999992847, 0.9999992847, 0.9999992847,\n",
            "          0.9999992847, 0.9999992847, 0.9999992847, 0.9999992847, 0.9999991655,\n",
            "          0.9999991655, 0.9999991059, 0.9999991059, 0.9999989867, 0.9999989271,\n",
            "          0.9999988079, 0.9999987483, 0.9999986291, 0.9999984503, 0.9999982715],\n",
            "         [0.9999985695, 0.9999986887, 0.9999988675, 0.9999989867, 0.9999990463,\n",
            "          0.9999991655, 0.9999992251, 0.9999992847, 0.9999993443, 0.9999994040,\n",
            "          0.9999994636, 0.9999994636, 0.9999994636, 0.9999994636, 0.9999994636,\n",
            "          0.9999994636, 0.9999995232, 0.9999995232, 0.9999994636, 0.9999994040,\n",
            "          0.9999994040, 0.9999993443, 0.9999993443, 0.9999992847, 0.9999992251,\n",
            "          0.9999991655, 0.9999990463, 0.9999989271, 0.9999988079, 0.9999986291],\n",
            "         [0.9999988079, 0.9999989867, 0.9999991059, 0.9999991655, 0.9999992847,\n",
            "          0.9999993443, 0.9999994040, 0.9999994040, 0.9999993443, 0.9999993443,\n",
            "          0.9999994040, 0.9999995232, 0.9999995828, 0.9999995828, 0.9999996424,\n",
            "          0.9999996424, 0.9999996424, 0.9999996424, 0.9999996424, 0.9999996424,\n",
            "          0.9999995828, 0.9999995828, 0.9999995828, 0.9999995232, 0.9999995232,\n",
            "          0.9999994636, 0.9999994040, 0.9999992847, 0.9999991655, 0.9999989867],\n",
            "         [0.9999990463, 0.9999991059, 0.9999992251, 0.9999992847, 0.9999994040,\n",
            "          0.9999994040, 0.9999994636, 0.9999992847, 0.9999977946, 0.9999958277,\n",
            "          0.9999971986, 0.9999992847, 0.9999996424, 0.9999997020, 0.9999997020,\n",
            "          0.9999997616, 0.9999997616, 0.9999997616, 0.9999997616, 0.9999997616,\n",
            "          0.9999997616, 0.9999997616, 0.9999997616, 0.9999997020, 0.9999997020,\n",
            "          0.9999997020, 0.9999996424, 0.9999995828, 0.9999995232, 0.9999994040],\n",
            "         [0.9999991655, 0.9999992251, 0.9999993443, 0.9999994040, 0.9999994636,\n",
            "          0.9999995232, 0.9999995828, 0.9999991655, 0.9999906421, 0.9999442101,\n",
            "          0.9999734759, 0.9999982715, 0.9999997020, 0.9999997020, 0.9999997020,\n",
            "          0.9999995828, 0.9999995232, 0.9999995828, 0.9999997616, 0.9999998212,\n",
            "          0.9999998212, 0.9999998212, 0.9999998212, 0.9999998212, 0.9999998212,\n",
            "          0.9999998212, 0.9999998212, 0.9999997616, 0.9999997020, 0.9999997020],\n",
            "         [0.9999992847, 0.9999993443, 0.9999994636, 0.9999992847, 0.9999990463,\n",
            "          0.9999989867, 0.9999994040, 0.9999989867, 0.9999577999, 0.9990778565,\n",
            "          0.9996631145, 0.9999934435, 0.9999996424, 0.9999996424, 0.9999987483,\n",
            "          0.9999936819, 0.9999804497, 0.9999921322, 0.9999986291, 0.9999997616,\n",
            "          0.9999998212, 0.9999998212, 0.9999998808, 0.9999998808, 0.9999998808,\n",
            "          0.9999998808, 0.9999998808, 0.9999998808, 0.9999998212, 0.9999998212],\n",
            "         [0.9999994040, 0.9999994636, 0.9999995232, 0.9999991059, 0.9999959469,\n",
            "          0.9999880791, 0.9999933243, 0.9999960065, 0.9999139905, 0.9969639182,\n",
            "          0.9978006482, 0.9999707937, 0.9999992847, 0.9999994636, 0.9999927282,\n",
            "          0.9998430014, 0.9990693331, 0.9997316003, 0.9999854565, 0.9999991655,\n",
            "          0.9999998212, 0.9999998808, 0.9999998808, 0.9999998808, 0.9999998808,\n",
            "          0.9999998808, 0.9999998808, 0.9999998808, 0.9999998808, 0.9999998808],\n",
            "         [0.9999994040, 0.9999994636, 0.9999995828, 0.9999991655, 0.9999944568,\n",
            "          0.9999624491, 0.9999371767, 0.9999421835, 0.9994860888, 0.9909620285,\n",
            "          0.9901639819, 0.9998284578, 0.9999971986, 0.9999982119, 0.9999263883,\n",
            "          0.9959318042, 0.9750034213, 0.9932028651, 0.9997565746, 0.9999951124,\n",
            "          0.9999997020, 0.9999998808, 0.9999998808, 0.9999998808, 0.9999998808,\n",
            "          0.9999998808, 0.9999998808, 0.9999998808, 0.9999998808, 0.9999998808],\n",
            "         [0.9999994040, 0.9999995232, 0.9999995828, 0.9999992847, 0.9999964237,\n",
            "          0.9999744296, 0.9998956919, 0.9996898770, 0.9970050454, 0.9708765149,\n",
            "          0.9648280740, 0.9981931448, 0.9999310970, 0.9999572635, 0.9991815090,\n",
            "          0.9857643843, 0.9586121440, 0.9754170179, 0.9974021912, 0.9999537468,\n",
            "          0.9999988675, 0.9999998212, 0.9999998808, 0.9999998808, 0.9999998808,\n",
            "          0.9999998808, 0.9999998808, 0.9999998808, 0.9999998808, 0.9999998808],\n",
            "         [0.9999994636, 0.9999995232, 0.9999995828, 0.9999995828, 0.9999993443,\n",
            "          0.9999974966, 0.9999817014, 0.9998123050, 0.9964314103, 0.9596753716,\n",
            "          0.9113832116, 0.9838981032, 0.9981799126, 0.9988289475, 0.9950038791,\n",
            "          0.9795349836, 0.9660499096, 0.9663078189, 0.9874982834, 0.9995481968,\n",
            "          0.9999928474, 0.9999996424, 0.9999998808, 0.9999998808, 0.9999998808,\n",
            "          0.9999998808, 0.9999998808, 0.9999998808, 0.9999998808, 0.9999998808],\n",
            "         [0.9999994636, 0.9999995232, 0.9999996424, 0.9999996424, 0.9999997020,\n",
            "          0.9999995828, 0.9999987483, 0.9999783635, 0.9987583756, 0.9626684189,\n",
            "          0.8347072601, 0.8951739669, 0.9510260224, 0.9671612382, 0.9681472778,\n",
            "          0.9650349617, 0.9628953934, 0.9585393071, 0.9695133567, 0.9965106845,\n",
            "          0.9999170899, 0.9999978542, 0.9999997616, 0.9999998808, 0.9999998808,\n",
            "          0.9999998808, 0.9999998808, 0.9999998808, 0.9999998808, 0.9999998808],\n",
            "         [0.9999995232, 0.9999995828, 0.9999996424, 0.9999996424, 0.9999997020,\n",
            "          0.9999997020, 0.9999996424, 0.9999957681, 0.9995385408, 0.9569748640,\n",
            "          0.7681918144, 0.7906363606, 0.8321927786, 0.8671158552, 0.9058223963,\n",
            "          0.9280236959, 0.9319284558, 0.9374576211, 0.9513705373, 0.9839570522,\n",
            "          0.9986057281, 0.9999673963, 0.9999989271, 0.9999998212, 0.9999998808,\n",
            "          0.9999998808, 0.9999998808, 0.9999998808, 0.9999998808, 0.9999998808],\n",
            "         [0.9999994636, 0.9999995232, 0.9999995828, 0.9999996424, 0.9999996424,\n",
            "          0.9999997020, 0.9999996424, 0.9999944568, 0.9991987348, 0.9258520007,\n",
            "          0.7124758363, 0.7165168524, 0.7343086004, 0.7534844875, 0.8013011217,\n",
            "          0.8438414931, 0.8549199104, 0.8813205361, 0.9224442840, 0.9521238804,\n",
            "          0.9852093458, 0.9995312691, 0.9999938011, 0.9999997020, 0.9999998808,\n",
            "          0.9999998808, 0.9999998808, 0.9999998808, 0.9999998808, 0.9999998808],\n",
            "         [0.9999994636, 0.9999995232, 0.9999995828, 0.9999995828, 0.9999996424,\n",
            "          0.9999996424, 0.9999995232, 0.9999850392, 0.9977374077, 0.8746020198,\n",
            "          0.6981658340, 0.6974961162, 0.6867583990, 0.6824771762, 0.6905602813,\n",
            "          0.7061631083, 0.7204328775, 0.8010727763, 0.8743186593, 0.9124982953,\n",
            "          0.9468403459, 0.9966023564, 0.9999647737, 0.9999992847, 0.9999998808,\n",
            "          0.9999998808, 0.9999998808, 0.9999998808, 0.9999998808, 0.9999998808],\n",
            "         [0.9999994636, 0.9999995232, 0.9999995828, 0.9999995828, 0.9999994040,\n",
            "          0.9999989867, 0.9999973774, 0.9999195337, 0.9937443733, 0.8332251906,\n",
            "          0.6819638610, 0.6863377094, 0.6891607642, 0.6874743104, 0.6722825766,\n",
            "          0.6627586484, 0.6617591977, 0.7261410952, 0.8040899634, 0.8830402493,\n",
            "          0.9380241036, 0.9893577695, 0.9997625351, 0.9999960661, 0.9999997616,\n",
            "          0.9999998808, 0.9999998808, 0.9999998808, 0.9999998808, 0.9999998808],\n",
            "         [0.9999992251, 0.9999987483, 0.9999980927, 0.9999967813, 0.9999927878,\n",
            "          0.9999725819, 0.9998849630, 0.9982912540, 0.9675996304, 0.7710449696,\n",
            "          0.6703488231, 0.6793802977, 0.6866358519, 0.6904817224, 0.6838516593,\n",
            "          0.6713967919, 0.6518761516, 0.6757071614, 0.7511045933, 0.8591871858,\n",
            "          0.9316999316, 0.9743333459, 0.9977287650, 0.9999409318, 0.9999983907,\n",
            "          0.9999997616, 0.9999998808, 0.9999998808, 0.9999998808, 0.9999998808],\n",
            "         [0.9999977946, 0.9999876618, 0.9999374747, 0.9998515844, 0.9996613264,\n",
            "          0.9985772371, 0.9949696064, 0.9755913019, 0.8894585967, 0.7261745334,\n",
            "          0.6579085588, 0.6616029143, 0.6691459417, 0.6757180095, 0.6746003628,\n",
            "          0.6599330902, 0.6401644349, 0.6475828290, 0.7041581869, 0.8117076755,\n",
            "          0.9057569504, 0.9482902884, 0.9857201576, 0.9988457561, 0.9999706149,\n",
            "          0.9999987483, 0.9999998212, 0.9999998808, 0.9999998808, 0.9999998808],\n",
            "         [0.9999917150, 0.9998021722, 0.9971750379, 0.9926276207, 0.9857861400,\n",
            "          0.9621600509, 0.9203495979, 0.8631545305, 0.7924132347, 0.7123261690,\n",
            "          0.6627991199, 0.6496787071, 0.6541554928, 0.6530293226, 0.6498214602,\n",
            "          0.6375867724, 0.6235496998, 0.6283384562, 0.6674425602, 0.7427290678,\n",
            "          0.8500500321, 0.9204127192, 0.9631279111, 0.9896501303, 0.9994131923,\n",
            "          0.9999885559, 0.9999995232, 0.9999998808, 0.9999998808, 0.9999998808],\n",
            "         [0.9999805689, 0.9986917377, 0.9649457335, 0.9147172570, 0.9004032612,\n",
            "          0.8824334741, 0.8631757498, 0.8453965187, 0.8045197129, 0.7391615510,\n",
            "          0.6727241874, 0.6446104646, 0.6365309358, 0.6243046522, 0.6069279313,\n",
            "          0.6021675467, 0.6035211086, 0.6243273020, 0.6480392218, 0.6892395616,\n",
            "          0.7860481739, 0.8963376284, 0.9489055872, 0.9682661295, 0.9947547317,\n",
            "          0.9999006987, 0.9999981523, 0.9999998212, 0.9999998808, 0.9999998808],\n",
            "         [0.9999902844, 0.9997292757, 0.9957398772, 0.9854092598, 0.9655281901,\n",
            "          0.9251692891, 0.8751651645, 0.8331049085, 0.7959541678, 0.7431079149,\n",
            "          0.6832888722, 0.6486892700, 0.6216428876, 0.6006626487, 0.5837168097,\n",
            "          0.5792940855, 0.5888035297, 0.6197925806, 0.6455743313, 0.6666899323,\n",
            "          0.7448608875, 0.8527839184, 0.9324387908, 0.9635986090, 0.9861931801,\n",
            "          0.9994668365, 0.9999917150, 0.9999997020, 0.9999998808, 0.9999998808],\n",
            "         [0.9999971986, 0.9999802709, 0.9998922348, 0.9996615648, 0.9988921285,\n",
            "          0.9961842299, 0.9879050851, 0.9670490623, 0.9243735671, 0.8556582332,\n",
            "          0.7710894942, 0.6959422231, 0.6277244687, 0.5848490000, 0.5696970224,\n",
            "          0.5734427571, 0.5907241106, 0.6221114993, 0.6490793824, 0.6729827523,\n",
            "          0.7210027575, 0.8003634214, 0.8846389651, 0.9451936483, 0.9732680321,\n",
            "          0.9975076318, 0.9999577999, 0.9999991059, 0.9999998808, 0.9999998808],\n",
            "         [0.9999989867, 0.9999980330, 0.9999957085, 0.9999889135, 0.9999629259,\n",
            "          0.9998567700, 0.9994373918, 0.9977240562, 0.9906784892, 0.9683536291,\n",
            "          0.9220006466, 0.8615030646, 0.7953330278, 0.7337958217, 0.6904159188,\n",
            "          0.6642816663, 0.6584270597, 0.6583893299, 0.6621881723, 0.6752025485,\n",
            "          0.7069539428, 0.7681249380, 0.8429484367, 0.9135264754, 0.9458363652,\n",
            "          0.9887270331, 0.9997398853, 0.9999963641, 0.9999997616, 0.9999998808],\n",
            "         [0.9999982715, 0.9999973178, 0.9999958873, 0.9999934435, 0.9999882579,\n",
            "          0.9999747276, 0.9999261498, 0.9997062087, 0.9985111952, 0.9928926229,\n",
            "          0.9772181511, 0.9544813037, 0.9330433607, 0.9097648263, 0.8882562518,\n",
            "          0.8780462742, 0.8659777641, 0.8502992988, 0.8197414875, 0.7943559289,\n",
            "          0.7697371840, 0.7685971260, 0.7992258668, 0.8460714221, 0.8833514452,\n",
            "          0.9519654512, 0.9976890683, 0.9999738336, 0.9999992847, 0.9999998808],\n",
            "         [0.9999944568, 0.9999827147, 0.9999495745, 0.9998935461, 0.9998492002,\n",
            "          0.9998201728, 0.9997451305, 0.9995007515, 0.9985552430, 0.9951225519,\n",
            "          0.9875554442, 0.9793890715, 0.9736490846, 0.9670655727, 0.9640318751,\n",
            "          0.9674732089, 0.9727724791, 0.9730873704, 0.9726838470, 0.9737526774,\n",
            "          0.9735082984, 0.9719592929, 0.9676184058, 0.9580335617, 0.9440172315,\n",
            "          0.9586775303, 0.9946501851, 0.9999112487, 0.9999983311, 0.9999998212],\n",
            "         [0.9999815226, 0.9998860955, 0.9993673563, 0.9980902672, 0.9972621202,\n",
            "          0.9971987009, 0.9969711304, 0.9962415695, 0.9941983223, 0.9896826744,\n",
            "          0.9841411710, 0.9813234806, 0.9815264940, 0.9816309214, 0.9834704399,\n",
            "          0.9879034162, 0.9920753241, 0.9938862920, 0.9954879284, 0.9968520403,\n",
            "          0.9979536533, 0.9986249804, 0.9989302754, 0.9989275932, 0.9985886216,\n",
            "          0.9985517859, 0.9995063543, 0.9999734759, 0.9999988675, 0.9999998212],\n",
            "         [0.9999670386, 0.9996830225, 0.9974327087, 0.9906151295, 0.9854174852,\n",
            "          0.9837747216, 0.9824321866, 0.9808328152, 0.9785424471, 0.9745787978,\n",
            "          0.9716238976, 0.9714395404, 0.9738552570, 0.9760739803, 0.9808968306,\n",
            "          0.9872987270, 0.9931560755, 0.9965487123, 0.9985359907, 0.9994447827,\n",
            "          0.9998021126, 0.9999175072, 0.9999554157, 0.9999696612, 0.9999724627,\n",
            "          0.9999752641, 0.9999866486, 0.9999973178, 0.9999995232, 0.9999998212],\n",
            "         [0.9999769926, 0.9997754693, 0.9979832768, 0.9912639856, 0.9837722778,\n",
            "          0.9797327518, 0.9762728810, 0.9725941420, 0.9687293768, 0.9657930732,\n",
            "          0.9649780989, 0.9660170674, 0.9680629969, 0.9697337747, 0.9728257060,\n",
            "          0.9775100946, 0.9863377810, 0.9937447906, 0.9978221059, 0.9994070530,\n",
            "          0.9998661280, 0.9999698400, 0.9999917746, 0.9999971390, 0.9999986291,\n",
            "          0.9999991655, 0.9999995232, 0.9999997020, 0.9999998212, 0.9999998808],\n",
            "         [0.9999917150, 0.9999446869, 0.9995411038, 0.9971837997, 0.9906774163,\n",
            "          0.9826634526, 0.9765684605, 0.9724673629, 0.9685601592, 0.9651891589,\n",
            "          0.9630560875, 0.9624291658, 0.9631707668, 0.9641532302, 0.9639246464,\n",
            "          0.9662981629, 0.9760621786, 0.9883813262, 0.9959837794, 0.9989280105,\n",
            "          0.9997472763, 0.9999427199, 0.9999862313, 0.9999964833, 0.9999989867,\n",
            "          0.9999996424, 0.9999997616, 0.9999998212, 0.9999998212, 0.9999998212],\n",
            "         [0.9999975562, 0.9999915957, 0.9999552965, 0.9997133017, 0.9984217286,\n",
            "          0.9940329194, 0.9852756262, 0.9760900736, 0.9695506692, 0.9658246040,\n",
            "          0.9632835388, 0.9612882137, 0.9604090452, 0.9605847597, 0.9616549611,\n",
            "          0.9647610784, 0.9722639322, 0.9843782783, 0.9940492511, 0.9983131289,\n",
            "          0.9995791316, 0.9998990893, 0.9999758005, 0.9999938607, 0.9999982119,\n",
            "          0.9999993443, 0.9999997020, 0.9999998212, 0.9999998212, 0.9999998212],\n",
            "         [0.9999989271, 0.9999981523, 0.9999950528, 0.9999789000, 0.9998853207,\n",
            "          0.9993839860, 0.9972909093, 0.9914433956, 0.9815612435, 0.9718105197,\n",
            "          0.9657704234, 0.9624832869, 0.9611668587, 0.9618129730, 0.9637833238,\n",
            "          0.9669687748, 0.9722741246, 0.9820203185, 0.9920955300, 0.9974455833,\n",
            "          0.9993034005, 0.9998233318, 0.9999582171, 0.9999899268, 0.9999972582,\n",
            "          0.9999990463, 0.9999995828, 0.9999997616, 0.9999998212, 0.9999998212]]])\n",
            "avg pooling output= tensor([[[0.9999987483, 0.9999990463, 0.9999992847, 0.9999993443, 0.9999994636,\n",
            "          0.9999994636, 0.9999993443, 0.9999993443, 0.9999991655, 0.9999988079],\n",
            "         [0.9999992847, 0.9999992847, 0.9999936223, 0.9998492002, 0.9999995828,\n",
            "          0.9999959469, 0.9999995828, 0.9999997616, 0.9999997616, 0.9999997616],\n",
            "         [0.9999994636, 0.9999899268, 0.9995399117, 0.9899542332, 0.9998870492,\n",
            "          0.9869529009, 0.9996767044, 0.9999997616, 0.9999997616, 0.9999997616],\n",
            "         [0.9999995828, 0.9999993443, 0.9993883967, 0.8959233165, 0.9426087141,\n",
            "          0.9550857544, 0.9874348044, 0.9999959469, 0.9999997616, 0.9999997616],\n",
            "         [0.9999995828, 0.9999995828, 0.9989528656, 0.7585150599, 0.7108675838,\n",
            "          0.7620455623, 0.9131765366, 0.9983562827, 0.9999997616, 0.9999997616],\n",
            "         [0.9996542335, 0.9931806922, 0.9335235953, 0.6879182458, 0.6708266735,\n",
            "          0.6484594941, 0.8026484251, 0.9753389359, 0.9999298453, 0.9999997616],\n",
            "         [0.9954386950, 0.9520443678, 0.8774049282, 0.7171413898, 0.6062285304,\n",
            "          0.6004649401, 0.6915019155, 0.9102807641, 0.9945598245, 0.9999997616],\n",
            "         [0.9999900460, 0.9999253154, 0.9981982708, 0.9598351717, 0.8728172779,\n",
            "          0.8320838213, 0.8164582253, 0.8706783652, 0.9627392888, 0.9999864101],\n",
            "         [0.9993393421, 0.9896808267, 0.9829794765, 0.9743974209, 0.9764529467,\n",
            "          0.9898290634, 0.9983523488, 0.9995871782, 0.9996197820, 0.9999964237],\n",
            "         [0.9999349117, 0.9957711697, 0.9798675179, 0.9645705819, 0.9622955322,\n",
            "          0.9748232365, 0.9972716570, 0.9999516606, 0.9999990463, 0.9999997616]]])\n",
            "max pooling output= tensor([[[0.9999991059, 0.9999993443, 0.9999994040, 0.9999995232, 0.9999996424,\n",
            "          0.9999996424, 0.9999996424, 0.9999995828, 0.9999995232, 0.9999992847],\n",
            "         [0.9999994636, 0.9999995232, 0.9999995828, 0.9999992847, 0.9999997020,\n",
            "          0.9999997616, 0.9999998212, 0.9999998808, 0.9999998808, 0.9999998808],\n",
            "         [0.9999995828, 0.9999992847, 0.9999960065, 0.9999707937, 0.9999994636,\n",
            "          0.9998430014, 0.9999998212, 0.9999998808, 0.9999998808, 0.9999998808],\n",
            "         [0.9999996424, 0.9999997020, 0.9999996424, 0.9838981032, 0.9988289475,\n",
            "          0.9795349836, 0.9999928474, 0.9999998808, 0.9999998808, 0.9999998808],\n",
            "         [0.9999995828, 0.9999997020, 0.9999996424, 0.9258520007, 0.8013011217,\n",
            "          0.8813205361, 0.9852093458, 0.9999997020, 0.9999998808, 0.9999998808],\n",
            "         [0.9999992251, 0.9999967813, 0.9998849630, 0.7710449696, 0.6904817224,\n",
            "          0.6757071614, 0.9316999316, 0.9999409318, 0.9999998808, 0.9999998808],\n",
            "         [0.9999971986, 0.9996615648, 0.9879050851, 0.8556582332, 0.6365309358,\n",
            "          0.6243273020, 0.7860481739, 0.9682661295, 0.9999981523, 0.9999998808],\n",
            "         [0.9999989867, 0.9999934435, 0.9999261498, 0.9951225519, 0.9736490846,\n",
            "          0.9730873704, 0.9737526774, 0.9719592929, 0.9997398853, 0.9999998808],\n",
            "         [0.9999815226, 0.9980902672, 0.9969711304, 0.9896826744, 0.9834704399,\n",
            "          0.9965487123, 0.9998661280, 0.9999971390, 0.9999995232, 0.9999998808],\n",
            "         [0.9999989271, 0.9999789000, 0.9972909093, 0.9718105197, 0.9641532302,\n",
            "          0.9883813262, 0.9997472763, 0.9999964833, 0.9999997616, 0.9999998212]]])\n"
          ]
        }
      ],
      "source": [
        "#testng pooling function\n",
        "inp =  conv_output\n",
        "stride=torch.tensor([3,3])\n",
        "\n",
        "#printing input activation map\n",
        "print('input activation map=',inp)\n",
        "\n",
        "#print pooled outputs\n",
        "print('avg pooling output=',pooling_function(inp,stride,avg_pool))\n",
        "print('max pooling output=',pooling_function(inp,stride,max_pool))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bat7tJrfAKJA"
      },
      "source": [
        "**QUESTION 3**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<Font size=2>**Convolution Layer Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {
        "id": "Qc6lXuwzAJRI"
      },
      "outputs": [],
      "source": [
        "def convolution_layer_function(input,number_of_filters,kernel_dimensions,stride=torch.tensor([1,1]),padding=torch.tensor([0,0]),non_linear_function=sigmoid,kernel=None):\n",
        "  \n",
        "  #randomly initializing kernel if no kernel is given\n",
        "  if kernel==None:\n",
        "    kernel=torch.rand([number_of_filters,input.shape[0],kernel_dimensions[0],kernel_dimensions[1]])\n",
        "\n",
        "  #applying convolution for given number of filters\n",
        "  for i in range(number_of_filters):\n",
        "    if i==0:\n",
        "      output=convolution_function(input,kernel[i],stride,padding,non_linear_function)\n",
        "    else:\n",
        "      output=torch.cat((output,convolution_function(input,kernel[i],stride,padding,non_linear_function)))\n",
        "\n",
        "      \n",
        "  return output"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<Font size=2>**Printing outputs**\\\n",
        "prints input image,filter kernel and output activation map for different activation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipNVUBCMDj2f",
        "outputId": "f3362d90-1832-4de9-c07b-6bd839a0d216"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input image=\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "filter kernel= tensor([[[[0.4673201442, 0.6773141026, 0.5897606015],\n",
            "          [0.2458706498, 0.2010659575, 0.3820259571],\n",
            "          [0.9840633273, 0.2748239636, 0.8604996800]],\n",
            "\n",
            "         [[0.7687978745, 0.6626182795, 0.7198022604],\n",
            "          [0.8228549957, 0.9433235526, 0.2695923448],\n",
            "          [0.4867876768, 0.5752925873, 0.1459161639]],\n",
            "\n",
            "         [[0.9439978600, 0.7113342285, 0.7732119560],\n",
            "          [0.2823778987, 0.1075371504, 0.5777339935],\n",
            "          [0.7078145742, 0.5011283755, 0.6453835964]]],\n",
            "\n",
            "\n",
            "        [[[0.4076392651, 0.0728557110, 0.2639546394],\n",
            "          [0.9357873201, 0.7145095468, 0.5950982571],\n",
            "          [0.3375608325, 0.8435733318, 0.9041685462]],\n",
            "\n",
            "         [[0.2865129709, 0.8995865583, 0.7063716650],\n",
            "          [0.7555588484, 0.9348893166, 0.1382843852],\n",
            "          [0.7246071696, 0.7431226969, 0.9103741646]],\n",
            "\n",
            "         [[0.2124872208, 0.9642084837, 0.2802757621],\n",
            "          [0.4853015542, 0.7866694331, 0.3642090559],\n",
            "          [0.5517060161, 0.4613213539, 0.0111625195]]],\n",
            "\n",
            "\n",
            "        [[[0.6518630981, 0.9990981221, 0.8204446435],\n",
            "          [0.7766855955, 0.5215321779, 0.4995229840],\n",
            "          [0.0441773534, 0.6043426394, 0.4229001999]],\n",
            "\n",
            "         [[0.1619821787, 0.1415656209, 0.4715542793],\n",
            "          [0.0282376409, 0.6948249340, 0.9268266559],\n",
            "          [0.7258773446, 0.6685107946, 0.1251459718]],\n",
            "\n",
            "         [[0.7387678027, 0.9876539707, 0.4737645388],\n",
            "          [0.2049347162, 0.5464898944, 0.9479020238],\n",
            "          [0.6333171129, 0.3393435478, 0.7470908761]]],\n",
            "\n",
            "\n",
            "        [[[0.9661138654, 0.3574247956, 0.8280462027],\n",
            "          [0.1052814126, 0.2446174622, 0.5007278919],\n",
            "          [0.7569437027, 0.5488004684, 0.9333870411]],\n",
            "\n",
            "         [[0.3159685731, 0.2672397494, 0.2411910892],\n",
            "          [0.8997616768, 0.0342059731, 0.0067678094],\n",
            "          [0.5130570531, 0.2575971484, 0.1578027010]],\n",
            "\n",
            "         [[0.9163069725, 0.9347395301, 0.5550087094],\n",
            "          [0.0435064435, 0.4561592937, 0.4816529155],\n",
            "          [0.0176452994, 0.5335220098, 0.8041106462]]],\n",
            "\n",
            "\n",
            "        [[[0.2791175246, 0.0197809935, 0.2612837553],\n",
            "          [0.9951034188, 0.2956913114, 0.3000267148],\n",
            "          [0.6749055982, 0.4182638526, 0.6895632148]],\n",
            "\n",
            "         [[0.9613506794, 0.6537359953, 0.6825675964],\n",
            "          [0.3931245208, 0.3738021255, 0.2290700674],\n",
            "          [0.1572868228, 0.2909644842, 0.3444737792]],\n",
            "\n",
            "         [[0.4059802890, 0.4522240162, 0.4306809902],\n",
            "          [0.5011183023, 0.9958889484, 0.8323252201],\n",
            "          [0.7069461346, 0.0939564705, 0.7833647728]]],\n",
            "\n",
            "\n",
            "        [[[0.1501018405, 0.3695340157, 0.5606180429],\n",
            "          [0.3621734381, 0.1527079344, 0.5822679996],\n",
            "          [0.5815410614, 0.3711690307, 0.7051763535]],\n",
            "\n",
            "         [[0.4896566272, 0.5427953005, 0.3441503048],\n",
            "          [0.7079406381, 0.6844413280, 0.6952723861],\n",
            "          [0.7323596478, 0.9360427260, 0.6810093522]],\n",
            "\n",
            "         [[0.6583387256, 0.8833865523, 0.8904661536],\n",
            "          [0.9925467372, 0.7987088561, 0.8041887283],\n",
            "          [0.1182654500, 0.8234967589, 0.7481555939]]],\n",
            "\n",
            "\n",
            "        [[[0.3779584169, 0.7236270905, 0.1482031941],\n",
            "          [0.3655055761, 0.4045909047, 0.8594378829],\n",
            "          [0.2251236439, 0.9324813485, 0.3852030635]],\n",
            "\n",
            "         [[0.9162949324, 0.9136478305, 0.3214940429],\n",
            "          [0.3463087082, 0.1132223606, 0.8310513496],\n",
            "          [0.9380742908, 0.0407110453, 0.2619330883]],\n",
            "\n",
            "         [[0.5562016368, 0.2089847326, 0.6823472381],\n",
            "          [0.2140427232, 0.2045666575, 0.7720051408],\n",
            "          [0.4947381616, 0.6177633405, 0.3466975093]]],\n",
            "\n",
            "\n",
            "        [[[0.4841515422, 0.6790328622, 0.2729427218],\n",
            "          [0.6860267520, 0.7941586375, 0.6997168660],\n",
            "          [0.0566234589, 0.6449521184, 0.8916973472]],\n",
            "\n",
            "         [[0.6909934282, 0.6015740633, 0.6384569407],\n",
            "          [0.0672487020, 0.0291345716, 0.8950990438],\n",
            "          [0.2647799850, 0.7375019193, 0.0374370217]],\n",
            "\n",
            "         [[0.1153361797, 0.8876731396, 0.1976240277],\n",
            "          [0.0437036753, 0.1743056774, 0.3566359282],\n",
            "          [0.6166786551, 0.7101941705, 0.4955514073]]]])\n",
            "SIGMOID output activation map= tensor([[[0.9968085289, 0.9972109199, 0.9978395104,  ..., 0.9949443340,\n",
            "          0.9962555766, 0.9945847988],\n",
            "         [0.9919607043, 0.9928235412, 0.9940021634,  ..., 0.9969465137,\n",
            "          0.9981991053, 0.9971920252],\n",
            "         [0.9889362454, 0.9913248420, 0.9937562943,  ..., 0.9977742434,\n",
            "          0.9987712502, 0.9985278845],\n",
            "         ...,\n",
            "         [0.9997484088, 0.9997076392, 0.9996873140,  ..., 0.9835728407,\n",
            "          0.9926624894, 0.9966350198],\n",
            "         [0.9997806549, 0.9997646213, 0.9997476339,  ..., 0.9783036113,\n",
            "          0.9882839322, 0.9943957329],\n",
            "         [0.9998308420, 0.9998200536, 0.9998026490,  ..., 0.9789892435,\n",
            "          0.9862688184, 0.9921088219]],\n",
            "\n",
            "        [[0.9964477420, 0.9968137145, 0.9976077080,  ..., 0.9960563779,\n",
            "          0.9973738790, 0.9965733886],\n",
            "         [0.9906333089, 0.9909416437, 0.9942150712,  ..., 0.9974722862,\n",
            "          0.9986022711, 0.9981396794],\n",
            "         [0.9893713593, 0.9905620813, 0.9943696260,  ..., 0.9977580905,\n",
            "          0.9988049865, 0.9986816049],\n",
            "         ...,\n",
            "         [0.9998300076, 0.9998118877, 0.9998069406,  ..., 0.9856657386,\n",
            "          0.9936469197, 0.9972909093],\n",
            "         [0.9998580813, 0.9998505116, 0.9998462200,  ..., 0.9827045798,\n",
            "          0.9907218814, 0.9956560135],\n",
            "         [0.9998902082, 0.9998838305, 0.9998785257,  ..., 0.9844238162,\n",
            "          0.9898474216, 0.9942095280]],\n",
            "\n",
            "        [[0.9969489574, 0.9976245761, 0.9978998303,  ..., 0.9946298599,\n",
            "          0.9961506128, 0.9939134121],\n",
            "         [0.9923377633, 0.9936771989, 0.9946689010,  ..., 0.9968787432,\n",
            "          0.9982059598, 0.9970640540],\n",
            "         [0.9872252345, 0.9907932878, 0.9942651391,  ..., 0.9975568056,\n",
            "          0.9987338185, 0.9982089996],\n",
            "         ...,\n",
            "         [0.9997437000, 0.9997230172, 0.9996911883,  ..., 0.9865445495,\n",
            "          0.9943171740, 0.9974206686],\n",
            "         [0.9997791052, 0.9997763634, 0.9997552633,  ..., 0.9811990261,\n",
            "          0.9905644059, 0.9956611395],\n",
            "         [0.9998296499, 0.9998261333, 0.9998075962,  ..., 0.9822139740,\n",
            "          0.9891040921, 0.9938446283]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.9964908957, 0.9971982837, 0.9979671240,  ..., 0.9962664843,\n",
            "          0.9974030852, 0.9962455034],\n",
            "         [0.9915474057, 0.9928101897, 0.9951894283,  ..., 0.9978153706,\n",
            "          0.9987197518, 0.9976844788],\n",
            "         [0.9899130464, 0.9927363992, 0.9957282543,  ..., 0.9984384179,\n",
            "          0.9991959333, 0.9985695481],\n",
            "         ...,\n",
            "         [0.9996747971, 0.9996360540, 0.9995993376,  ..., 0.9776875377,\n",
            "          0.9899486303, 0.9954885840],\n",
            "         [0.9997327328, 0.9997198582, 0.9996920228,  ..., 0.9704232812,\n",
            "          0.9841871858, 0.9923980236],\n",
            "         [0.9997999668, 0.9997933507, 0.9997677803,  ..., 0.9719137549,\n",
            "          0.9813056588, 0.9891079664]],\n",
            "\n",
            "        [[0.9937006235, 0.9943265319, 0.9946865439,  ..., 0.9911651015,\n",
            "          0.9930566549, 0.9893254042],\n",
            "         [0.9843259454, 0.9869319797, 0.9890669584,  ..., 0.9937967658,\n",
            "          0.9965078831, 0.9943270683],\n",
            "         [0.9781053066, 0.9845498204, 0.9893811941,  ..., 0.9944368601,\n",
            "          0.9973577261, 0.9965869188],\n",
            "         ...,\n",
            "         [0.9994009137, 0.9993334413, 0.9992558956,  ..., 0.9763731360,\n",
            "          0.9886341691, 0.9943032265],\n",
            "         [0.9994624853, 0.9994391799, 0.9993910789,  ..., 0.9702185988,\n",
            "          0.9828531742, 0.9912381172],\n",
            "         [0.9995721579, 0.9995549321, 0.9995048046,  ..., 0.9718183279,\n",
            "          0.9808005095, 0.9880774021]],\n",
            "\n",
            "        [[0.9938634634, 0.9946275353, 0.9950474501,  ..., 0.9915135503,\n",
            "          0.9932594299, 0.9889962673],\n",
            "         [0.9843977690, 0.9869195819, 0.9899774194,  ..., 0.9939044714,\n",
            "          0.9965662956, 0.9943555593],\n",
            "         [0.9783049822, 0.9835210443, 0.9891062975,  ..., 0.9947980046,\n",
            "          0.9975598454, 0.9965061545],\n",
            "         ...,\n",
            "         [0.9995312095, 0.9995008707, 0.9994613528,  ..., 0.9825587869,\n",
            "          0.9919570684, 0.9961190224],\n",
            "         [0.9995795488, 0.9995751977, 0.9995530248,  ..., 0.9781408310,\n",
            "          0.9881407022, 0.9940559268],\n",
            "         [0.9996614456, 0.9996540546, 0.9996302724,  ..., 0.9798066020,\n",
            "          0.9866347313, 0.9918367267]]])\n",
            "RELU output activation map= tensor([[[5.7440724373, 5.8792467117, 6.1352486610,  ..., 5.2821764946,\n",
            "          5.5837292671, 5.2131114006],\n",
            "         [4.8153400421, 4.9297428131, 5.1103372574,  ..., 5.7884106636,\n",
            "          6.3176541328, 5.8724775314],\n",
            "         [4.4929533005, 4.7385787964, 5.0699152946,  ..., 6.1054391861,\n",
            "          6.7005190849, 6.5195751190],\n",
            "         ...,\n",
            "         [8.2875566483, 8.1372385025, 8.0700683594,  ..., 4.0922546387,\n",
            "          4.9073905945, 5.6909565926],\n",
            "         [8.4245443344, 8.3540267944, 8.2842884064,  ..., 3.8086752892,\n",
            "          4.4350109100, 5.1786122322],\n",
            "         [8.6844949722, 8.6228046417, 8.5303707123,  ..., 3.8414864540,\n",
            "          4.2742581367, 4.8340907097]],\n",
            "\n",
            "        [[5.6366128922, 5.7457141876, 6.0331058502,  ..., 5.5317058563,\n",
            "          5.9396276474, 5.6727561951],\n",
            "         [4.6611857414, 4.6949658394, 5.1467013359,  ..., 5.9778976440,\n",
            "          6.5714974403, 6.2851419449],\n",
            "         [4.5335173607, 4.6535348892, 5.1739306450,  ..., 6.0981955528,\n",
            "          6.7284202576, 6.6300354004],\n",
            "         ...,\n",
            "         [8.6795072556, 8.5782499313, 8.5521726608,  ..., 4.2306642532,\n",
            "          5.0524392128, 5.9084339142],\n",
            "         [8.8599920273, 8.8081665039, 8.7797603607,  ..., 4.0398678780,\n",
            "          4.6707763672, 5.4346055984],\n",
            "         [9.1167469025, 9.0601482391, 9.0159301758,  ..., 4.1463122368,\n",
            "          4.5798258781, 5.1457366943]],\n",
            "\n",
            "        [[5.7892107964, 6.0402126312, 6.1636238098,  ..., 5.2215132713,\n",
            "          5.5559883118, 5.0955672264],\n",
            "         [4.8637619019, 5.0572457314, 5.2288570404,  ..., 5.7664012909,\n",
            "          6.3214983940, 5.8277797699],\n",
            "         [4.3474283218, 4.6785707474, 5.1554422379,  ..., 6.0119972229,\n",
            "          6.6704616547, 6.3232016563],\n",
            "         ...,\n",
            "         [8.2688140869, 8.1912612915, 8.0824327469,  ..., 4.2948255539,\n",
            "          5.1646122932, 5.9576349258],\n",
            "         [8.4175262451, 8.4052639008, 8.3149929047,  ..., 3.9548671246,\n",
            "          4.6537866592, 5.4357986450],\n",
            "         [8.6773395538, 8.6571884155, 8.5556278229,  ..., 4.0113968849,\n",
            "          4.5084133148, 5.0842561722]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[5.6488800049, 5.8747258186, 6.1962699890,  ..., 5.5866684914,\n",
            "          5.9508228302, 5.5810446739],\n",
            "         [4.7647933960, 4.9278774261, 5.3321146965,  ..., 6.1241173744,\n",
            "          6.6594119072, 6.0658140182],\n",
            "         [4.5863714218, 4.9175863266, 5.4514575005,  ..., 6.4604907036,\n",
            "          7.1250009537, 6.5483489037],\n",
            "         ...,\n",
            "         [8.0308122635, 7.9180879593, 7.8220014572,  ..., 3.7800450325,\n",
            "          4.5899448395, 5.3966202736],\n",
            "         [8.2270078659, 8.1799488068, 8.0852136612,  ..., 3.4907450676,\n",
            "          4.1309952736, 4.8717160225],\n",
            "         [8.5167388916, 8.4842557907, 8.3676910400,  ..., 3.5439877510,\n",
            "          3.9606621265, 4.5087733269]],\n",
            "\n",
            "        [[5.0609836578, 5.1662678719, 5.2321844101,  ..., 4.7201690674,\n",
            "          4.9630031586, 4.5291571617],\n",
            "         [4.1399507523, 4.3244342804, 4.5049734116,  ..., 5.0764646530,\n",
            "          5.6537518501, 5.1663646698],\n",
            "         [3.7993729115, 4.1545600891, 4.5344510078,  ..., 5.1860113144,\n",
            "          5.9334588051, 5.6767191887],\n",
            "         ...,\n",
            "         [7.4194869995, 7.3127436638, 7.2025709152,  ..., 3.7214601040,\n",
            "          4.4657115936, 5.1621446609],\n",
            "         [7.5280218124, 7.4855947495, 7.4031805992,  ..., 3.4836375713,\n",
            "          4.0486464500, 4.7285456657],\n",
            "         [7.7562928200, 7.7168483734, 7.6100397110,  ..., 3.5404965878,\n",
            "          3.9334859848, 4.4173264503]],\n",
            "\n",
            "        [[5.0873403549, 5.2210779190, 5.3028907776,  ..., 4.7607631683,\n",
            "          4.9928512573, 4.4984550476],\n",
            "         [4.1446118355, 4.3234705925, 4.5928430557,  ..., 5.0940847397,\n",
            "          5.6706724167, 5.1714253426],\n",
            "         [3.8087399006, 4.0890555382, 4.5086169243,  ..., 5.2534976006,\n",
            "          6.0132393837, 5.6532502174],\n",
            "         ...,\n",
            "         [7.6648249626, 7.6021361351, 7.5258798599,  ..., 4.0313224792,\n",
            "          4.8148846626, 5.5477738380],\n",
            "         [7.7737131119, 7.7633967400, 7.7125539780,  ..., 3.8010332584,\n",
            "          4.4227142334, 5.1194009781],\n",
            "         [7.9904947281, 7.9688501358, 7.9023618698,  ..., 3.8819987774,\n",
            "          4.3016409874, 4.7999119759]]])\n",
            "tanh output activation map= tensor([[[0.9999794960, 0.9999843240, 0.9999906421,  ..., 0.9999483824,\n",
            "          0.9999718070, 0.9999406934],\n",
            "         [0.9998686910, 0.9998954535, 0.9999272823,  ..., 0.9999812841,\n",
            "          0.9999933839, 0.9999842048],\n",
            "         [0.9997497797, 0.9998468757, 0.9999210238,  ..., 0.9999900460,\n",
            "          0.9999970198, 0.9999957085],\n",
            "         ...,\n",
            "         [0.9999998808, 0.9999998808, 0.9999998212,  ..., 0.9994422793,\n",
            "          0.9998908043, 0.9999771118],\n",
            "         [1.0000000000, 1.0000000000, 0.9999998808,  ..., 0.9990167618,\n",
            "          0.9997189045, 0.9999365211],\n",
            "         [1.0000000000, 1.0000000000, 1.0000000000,  ..., 0.9990792274,\n",
            "          0.9996123910, 0.9998733997]],\n",
            "\n",
            "        [[0.9999745488, 0.9999794960, 0.9999884367,  ..., 0.9999687076,\n",
            "          0.9999861717, 0.9999762774],\n",
            "         [0.9998212457, 0.9998329282, 0.9999323487,  ..., 0.9999871850,\n",
            "          0.9999960661, 0.9999929667],\n",
            "         [0.9997692108, 0.9998184443, 0.9999358654,  ..., 0.9999898672,\n",
            "          0.9999970794, 0.9999964833],\n",
            "         ...,\n",
            "         [1.0000000000, 1.0000000000, 1.0000000000,  ..., 0.9995771646,\n",
            "          0.9999182224, 0.9999852180],\n",
            "         [1.0000000000, 1.0000000000, 1.0000000000,  ..., 0.9993806481,\n",
            "          0.9998247027, 0.9999619126],\n",
            "         [1.0000000000, 1.0000000000, 1.0000000000,  ..., 0.9994993806,\n",
            "          0.9997896552, 0.9999321103]],\n",
            "\n",
            "        [[0.9999813437, 0.9999886751, 0.9999911189,  ..., 0.9999416471,\n",
            "          0.9999700189, 0.9999250770],\n",
            "         [0.9998807907, 0.9999190569, 0.9999426007,  ..., 0.9999803305,\n",
            "          0.9999936223, 0.9999827743],\n",
            "         [0.9996652007, 0.9998273253, 0.9999334812,  ..., 0.9999880195,\n",
            "          0.9999967217, 0.9999936223],\n",
            "         ...,\n",
            "         [0.9999998808, 0.9999998808, 0.9999998212,  ..., 0.9996279478,\n",
            "          0.9999346137, 0.9999865890],\n",
            "         [1.0000000000, 1.0000000000, 0.9999998808,  ..., 0.9992659688,\n",
            "          0.9998185039, 0.9999619722],\n",
            "         [1.0000000000, 1.0000000000, 1.0000000000,  ..., 0.9993444085,\n",
            "          0.9997572899, 0.9999232888]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.9999752641, 0.9999842048, 0.9999916553,  ..., 0.9999718666,\n",
            "          0.9999864697, 0.9999716878],\n",
            "         [0.9998547435, 0.9998950362, 0.9999532104,  ..., 0.9999904037,\n",
            "          0.9999967217, 0.9999892116],\n",
            "         [0.9997922778, 0.9998928308, 0.9999632239,  ..., 0.9999950528,\n",
            "          0.9999986291, 0.9999960065],\n",
            "         ...,\n",
            "         [0.9999998212, 0.9999998212, 0.9999995828,  ..., 0.9989588261,\n",
            "          0.9997938275, 0.9999589324],\n",
            "         [0.9999998808, 0.9999998808, 0.9999998212,  ..., 0.9981437922,\n",
            "          0.9994838238, 0.9998826385],\n",
            "         [1.0000000000, 1.0000000000, 1.0000000000,  ..., 0.9983313084,\n",
            "          0.9992744327, 0.9997575879]],\n",
            "\n",
            "        [[0.9999197125, 0.9999348521, 0.9999429584,  ..., 0.9998411536,\n",
            "          0.9999023080, 0.9997672439],\n",
            "         [0.9994930625, 0.9996493459, 0.9997556210,  ..., 0.9999220967,\n",
            "          0.9999753833, 0.9999349117],\n",
            "         [0.9989983439, 0.9995075464, 0.9997696280,  ..., 0.9999373555,\n",
            "          0.9999859333, 0.9999765754],\n",
            "         ...,\n",
            "         [0.9999992847, 0.9999991655, 0.9999989271,  ..., 0.9988294244,\n",
            "          0.9997356534, 0.9999344349],\n",
            "         [0.9999994636, 0.9999993443, 0.9999992847,  ..., 0.9981172681,\n",
            "          0.9993914962, 0.9998437166],\n",
            "         [0.9999995828, 0.9999995828, 0.9999995232,  ..., 0.9983195066,\n",
            "          0.9992338419, 0.9997087717]],\n",
            "\n",
            "        [[0.9999237061, 0.9999416471, 0.9999504685,  ..., 0.9998534918,\n",
            "          0.9999078512, 0.9997525215],\n",
            "         [0.9994977117, 0.9996487498, 0.9997950196,  ..., 0.9999247789,\n",
            "          0.9999762177, 0.9999355674],\n",
            "         [0.9990170002, 0.9994387031, 0.9997573495,  ..., 0.9999452829,\n",
            "          0.9999880791, 0.9999753833],\n",
            "         ...,\n",
            "         [0.9999995232, 0.9999995232, 0.9999994636,  ..., 0.9993700385,\n",
            "          0.9998685122, 0.9999695420],\n",
            "         [0.9999995828, 0.9999995828, 0.9999995828,  ..., 0.9990017414,\n",
            "          0.9997119904, 0.9999284744],\n",
            "         [0.9999998212, 0.9999998212, 0.9999996424,  ..., 0.9991508126,\n",
            "          0.9996329546, 0.9998645186]]])\n",
            "PARAMETRIC RELU output activation map= tensor([[[5.7440724373, 5.8792467117, 6.1352486610,  ..., 5.2821764946,\n",
            "          5.5837292671, 5.2131114006],\n",
            "         [4.8153400421, 4.9297428131, 5.1103372574,  ..., 5.7884106636,\n",
            "          6.3176541328, 5.8724775314],\n",
            "         [4.4929533005, 4.7385787964, 5.0699152946,  ..., 6.1054391861,\n",
            "          6.7005190849, 6.5195751190],\n",
            "         ...,\n",
            "         [8.2875566483, 8.1372385025, 8.0700683594,  ..., 4.0922546387,\n",
            "          4.9073905945, 5.6909565926],\n",
            "         [8.4245443344, 8.3540267944, 8.2842884064,  ..., 3.8086752892,\n",
            "          4.4350109100, 5.1786122322],\n",
            "         [8.6844949722, 8.6228046417, 8.5303707123,  ..., 3.8414864540,\n",
            "          4.2742581367, 4.8340907097]],\n",
            "\n",
            "        [[5.6366128922, 5.7457141876, 6.0331058502,  ..., 5.5317058563,\n",
            "          5.9396276474, 5.6727561951],\n",
            "         [4.6611857414, 4.6949658394, 5.1467013359,  ..., 5.9778976440,\n",
            "          6.5714974403, 6.2851419449],\n",
            "         [4.5335173607, 4.6535348892, 5.1739306450,  ..., 6.0981955528,\n",
            "          6.7284202576, 6.6300354004],\n",
            "         ...,\n",
            "         [8.6795072556, 8.5782499313, 8.5521726608,  ..., 4.2306642532,\n",
            "          5.0524392128, 5.9084339142],\n",
            "         [8.8599920273, 8.8081665039, 8.7797603607,  ..., 4.0398678780,\n",
            "          4.6707763672, 5.4346055984],\n",
            "         [9.1167469025, 9.0601482391, 9.0159301758,  ..., 4.1463122368,\n",
            "          4.5798258781, 5.1457366943]],\n",
            "\n",
            "        [[5.7892107964, 6.0402126312, 6.1636238098,  ..., 5.2215132713,\n",
            "          5.5559883118, 5.0955672264],\n",
            "         [4.8637619019, 5.0572457314, 5.2288570404,  ..., 5.7664012909,\n",
            "          6.3214983940, 5.8277797699],\n",
            "         [4.3474283218, 4.6785707474, 5.1554422379,  ..., 6.0119972229,\n",
            "          6.6704616547, 6.3232016563],\n",
            "         ...,\n",
            "         [8.2688140869, 8.1912612915, 8.0824327469,  ..., 4.2948255539,\n",
            "          5.1646122932, 5.9576349258],\n",
            "         [8.4175262451, 8.4052639008, 8.3149929047,  ..., 3.9548671246,\n",
            "          4.6537866592, 5.4357986450],\n",
            "         [8.6773395538, 8.6571884155, 8.5556278229,  ..., 4.0113968849,\n",
            "          4.5084133148, 5.0842561722]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[5.6488800049, 5.8747258186, 6.1962699890,  ..., 5.5866684914,\n",
            "          5.9508228302, 5.5810446739],\n",
            "         [4.7647933960, 4.9278774261, 5.3321146965,  ..., 6.1241173744,\n",
            "          6.6594119072, 6.0658140182],\n",
            "         [4.5863714218, 4.9175863266, 5.4514575005,  ..., 6.4604907036,\n",
            "          7.1250009537, 6.5483489037],\n",
            "         ...,\n",
            "         [8.0308122635, 7.9180879593, 7.8220014572,  ..., 3.7800450325,\n",
            "          4.5899448395, 5.3966202736],\n",
            "         [8.2270078659, 8.1799488068, 8.0852136612,  ..., 3.4907450676,\n",
            "          4.1309952736, 4.8717160225],\n",
            "         [8.5167388916, 8.4842557907, 8.3676910400,  ..., 3.5439877510,\n",
            "          3.9606621265, 4.5087733269]],\n",
            "\n",
            "        [[5.0609836578, 5.1662678719, 5.2321844101,  ..., 4.7201690674,\n",
            "          4.9630031586, 4.5291571617],\n",
            "         [4.1399507523, 4.3244342804, 4.5049734116,  ..., 5.0764646530,\n",
            "          5.6537518501, 5.1663646698],\n",
            "         [3.7993729115, 4.1545600891, 4.5344510078,  ..., 5.1860113144,\n",
            "          5.9334588051, 5.6767191887],\n",
            "         ...,\n",
            "         [7.4194869995, 7.3127436638, 7.2025709152,  ..., 3.7214601040,\n",
            "          4.4657115936, 5.1621446609],\n",
            "         [7.5280218124, 7.4855947495, 7.4031805992,  ..., 3.4836375713,\n",
            "          4.0486464500, 4.7285456657],\n",
            "         [7.7562928200, 7.7168483734, 7.6100397110,  ..., 3.5404965878,\n",
            "          3.9334859848, 4.4173264503]],\n",
            "\n",
            "        [[5.0873403549, 5.2210779190, 5.3028907776,  ..., 4.7607631683,\n",
            "          4.9928512573, 4.4984550476],\n",
            "         [4.1446118355, 4.3234705925, 4.5928430557,  ..., 5.0940847397,\n",
            "          5.6706724167, 5.1714253426],\n",
            "         [3.8087399006, 4.0890555382, 4.5086169243,  ..., 5.2534976006,\n",
            "          6.0132393837, 5.6532502174],\n",
            "         ...,\n",
            "         [7.6648249626, 7.6021361351, 7.5258798599,  ..., 4.0313224792,\n",
            "          4.8148846626, 5.5477738380],\n",
            "         [7.7737131119, 7.7633967400, 7.7125539780,  ..., 3.8010332584,\n",
            "          4.4227142334, 5.1194009781],\n",
            "         [7.9904947281, 7.9688501358, 7.9023618698,  ..., 3.8819987774,\n",
            "          4.3016409874, 4.7999119759]]])\n"
          ]
        }
      ],
      "source": [
        "#testing convolution layer function\n",
        "inp =  image_list[1][1]\n",
        "kernel=torch.rand([8,inp.shape[0],3,3])\n",
        "\n",
        "#printing input image\n",
        "print('input image=')\n",
        "plt.imshow(inp.permute(1,2,0))\n",
        "plt.show()\n",
        "\n",
        "#printing filter kernel\n",
        "print('filter kernel=',kernel)\n",
        "\n",
        "conv_layer_output=convolution_layer_function(input=inp,number_of_filters=8,kernel_dimensions=torch.tensor([3,3]),kernel=kernel,non_linear_function=sigmoid)\n",
        "\n",
        "#print output activation map for different activation functions\n",
        "print('SIGMOID output activation map=',convolution_layer_function(input=inp,number_of_filters=8,kernel_dimensions=torch.tensor([3,3]),non_linear_function=sigmoid,kernel=kernel))\n",
        "print('RELU output activation map=',convolution_layer_function(input=inp,number_of_filters=8,kernel_dimensions=torch.tensor([3,3]),non_linear_function=RELU,kernel=kernel))\n",
        "print('tanh output activation map=',convolution_layer_function(input=inp,number_of_filters=8,kernel_dimensions=torch.tensor([3,3]),non_linear_function=tanh,kernel=kernel))\n",
        "print('PARAMETRIC RELU output activation map=',convolution_layer_function(input=inp,number_of_filters=8,kernel_dimensions=torch.tensor([3,3]),non_linear_function=parametric_RELU,kernel=kernel))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Verification that output has expected size:**\n",
        "\n",
        "Input size(NXHXW)=3X32X32\\\n",
        "kernel size(CXNXhXw)= 8X3X32X32\\\n",
        "stride=[1,1]\\\n",
        "padding=[0,0]\\\n",
        "Expected output height(H1)= ((H+2*padding[0]-h)//stride[0])+1=32-3+1=30\\\n",
        "Expected output width(W1)= ((H+2*padding[1]-h)//stride[1])+1=32-3+1=30\\\n",
        "Expected output size=(CXH1XW1)=(8X30X30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Expected  number of channels(C)=8  output number of channels= 8\n",
            "Expected height(H)=30  output height= 30\n",
            "Expected width(W)=30  output width= 30\n"
          ]
        }
      ],
      "source": [
        "print('Expected  number of channels(C)=8  output number of channels=',conv_layer_output.shape[0])\n",
        "print('Expected height(H)=30  output height=',conv_layer_output.shape[1])\n",
        "print('Expected width(W)=30  output width=',conv_layer_output.shape[2])\n",
        "#output has expected size"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Isb5Ax5TT9er"
      },
      "source": [
        "**QUESTION 4**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<Font size=2>**Global Average pooling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {
        "id": "DRt7lW5zt8Mo"
      },
      "outputs": [],
      "source": [
        "#returning stride(=shape of matrix) required for global average pooling\n",
        "def global_avg_pool(input):\n",
        "  return torch.tensor([input.shape[2],input.shape[1]])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<Font size=2> **POOLING LAYER FUNCTION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {
        "id": "aL4aa_NEUEiZ"
      },
      "outputs": [],
      "source": [
        "def pooling_layer_function(input,stride=torch.tensor([2,2]),pooling_func=global_avg_pool,kernel_size=None):\n",
        "\n",
        "  if kernel_size==None:\n",
        "    kernel_size=torch.tensor([stride[1],stride[0]])\n",
        "\n",
        "  #h,w are height and width of kernel\n",
        "  h=kernel_size[0]\n",
        "  w=kernel_size[1]\n",
        "\n",
        "  #H,W are height and width of kernel\n",
        "  H=input.shape[1]\n",
        "  W=input.shape[2]\n",
        "\n",
        "  #special case for global average pooling\n",
        "  if pooling_func==global_avg_pool:\n",
        "    #changing stride to shape of matrix and applying normal average pooling\n",
        "    stride=global_avg_pool(input)\n",
        "    pooling_func=avg_pool\n",
        "\n",
        "  #pooling function for input\n",
        "  for i in range(input.shape[0]):\n",
        "    if i==0:\n",
        "        output=pooling_function(input[i].reshape(1,H,W),stride,pooling_func)\n",
        "    else:\n",
        "        output=torch.cat((output,pooling_function(input[i].reshape(1,H,W),stride,pooling_func)))\n",
        "        \n",
        "\n",
        "  return output\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<Font size=2>**Printing outputs**\\\n",
        "prints input activation map,pooled output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input activation map= tensor([[[0.9968085289, 0.9972109199, 0.9978395104,  ..., 0.9949443340,\n",
            "          0.9962555766, 0.9945847988],\n",
            "         [0.9919607043, 0.9928235412, 0.9940021634,  ..., 0.9969465137,\n",
            "          0.9981991053, 0.9971920252],\n",
            "         [0.9889362454, 0.9913248420, 0.9937562943,  ..., 0.9977742434,\n",
            "          0.9987712502, 0.9985278845],\n",
            "         ...,\n",
            "         [0.9997484088, 0.9997076392, 0.9996873140,  ..., 0.9835728407,\n",
            "          0.9926624894, 0.9966350198],\n",
            "         [0.9997806549, 0.9997646213, 0.9997476339,  ..., 0.9783036113,\n",
            "          0.9882839322, 0.9943957329],\n",
            "         [0.9998308420, 0.9998200536, 0.9998026490,  ..., 0.9789892435,\n",
            "          0.9862688184, 0.9921088219]],\n",
            "\n",
            "        [[0.9964477420, 0.9968137145, 0.9976077080,  ..., 0.9960563779,\n",
            "          0.9973738790, 0.9965733886],\n",
            "         [0.9906333089, 0.9909416437, 0.9942150712,  ..., 0.9974722862,\n",
            "          0.9986022711, 0.9981396794],\n",
            "         [0.9893713593, 0.9905620813, 0.9943696260,  ..., 0.9977580905,\n",
            "          0.9988049865, 0.9986816049],\n",
            "         ...,\n",
            "         [0.9998300076, 0.9998118877, 0.9998069406,  ..., 0.9856657386,\n",
            "          0.9936469197, 0.9972909093],\n",
            "         [0.9998580813, 0.9998505116, 0.9998462200,  ..., 0.9827045798,\n",
            "          0.9907218814, 0.9956560135],\n",
            "         [0.9998902082, 0.9998838305, 0.9998785257,  ..., 0.9844238162,\n",
            "          0.9898474216, 0.9942095280]],\n",
            "\n",
            "        [[0.9969489574, 0.9976245761, 0.9978998303,  ..., 0.9946298599,\n",
            "          0.9961506128, 0.9939134121],\n",
            "         [0.9923377633, 0.9936771989, 0.9946689010,  ..., 0.9968787432,\n",
            "          0.9982059598, 0.9970640540],\n",
            "         [0.9872252345, 0.9907932878, 0.9942651391,  ..., 0.9975568056,\n",
            "          0.9987338185, 0.9982089996],\n",
            "         ...,\n",
            "         [0.9997437000, 0.9997230172, 0.9996911883,  ..., 0.9865445495,\n",
            "          0.9943171740, 0.9974206686],\n",
            "         [0.9997791052, 0.9997763634, 0.9997552633,  ..., 0.9811990261,\n",
            "          0.9905644059, 0.9956611395],\n",
            "         [0.9998296499, 0.9998261333, 0.9998075962,  ..., 0.9822139740,\n",
            "          0.9891040921, 0.9938446283]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.9964908957, 0.9971982837, 0.9979671240,  ..., 0.9962664843,\n",
            "          0.9974030852, 0.9962455034],\n",
            "         [0.9915474057, 0.9928101897, 0.9951894283,  ..., 0.9978153706,\n",
            "          0.9987197518, 0.9976844788],\n",
            "         [0.9899130464, 0.9927363992, 0.9957282543,  ..., 0.9984384179,\n",
            "          0.9991959333, 0.9985695481],\n",
            "         ...,\n",
            "         [0.9996747971, 0.9996360540, 0.9995993376,  ..., 0.9776875377,\n",
            "          0.9899486303, 0.9954885840],\n",
            "         [0.9997327328, 0.9997198582, 0.9996920228,  ..., 0.9704232812,\n",
            "          0.9841871858, 0.9923980236],\n",
            "         [0.9997999668, 0.9997933507, 0.9997677803,  ..., 0.9719137549,\n",
            "          0.9813056588, 0.9891079664]],\n",
            "\n",
            "        [[0.9937006235, 0.9943265319, 0.9946865439,  ..., 0.9911651015,\n",
            "          0.9930566549, 0.9893254042],\n",
            "         [0.9843259454, 0.9869319797, 0.9890669584,  ..., 0.9937967658,\n",
            "          0.9965078831, 0.9943270683],\n",
            "         [0.9781053066, 0.9845498204, 0.9893811941,  ..., 0.9944368601,\n",
            "          0.9973577261, 0.9965869188],\n",
            "         ...,\n",
            "         [0.9994009137, 0.9993334413, 0.9992558956,  ..., 0.9763731360,\n",
            "          0.9886341691, 0.9943032265],\n",
            "         [0.9994624853, 0.9994391799, 0.9993910789,  ..., 0.9702185988,\n",
            "          0.9828531742, 0.9912381172],\n",
            "         [0.9995721579, 0.9995549321, 0.9995048046,  ..., 0.9718183279,\n",
            "          0.9808005095, 0.9880774021]],\n",
            "\n",
            "        [[0.9938634634, 0.9946275353, 0.9950474501,  ..., 0.9915135503,\n",
            "          0.9932594299, 0.9889962673],\n",
            "         [0.9843977690, 0.9869195819, 0.9899774194,  ..., 0.9939044714,\n",
            "          0.9965662956, 0.9943555593],\n",
            "         [0.9783049822, 0.9835210443, 0.9891062975,  ..., 0.9947980046,\n",
            "          0.9975598454, 0.9965061545],\n",
            "         ...,\n",
            "         [0.9995312095, 0.9995008707, 0.9994613528,  ..., 0.9825587869,\n",
            "          0.9919570684, 0.9961190224],\n",
            "         [0.9995795488, 0.9995751977, 0.9995530248,  ..., 0.9781408310,\n",
            "          0.9881407022, 0.9940559268],\n",
            "         [0.9996614456, 0.9996540546, 0.9996302724,  ..., 0.9798066020,\n",
            "          0.9866347313, 0.9918367267]]])\n",
            "global pooling output= tensor([[[0.9712381363]],\n",
            "\n",
            "        [[0.9724752903]],\n",
            "\n",
            "        [[0.9731865525]],\n",
            "\n",
            "        [[0.9674990773]],\n",
            "\n",
            "        [[0.9586758018]],\n",
            "\n",
            "        [[0.9675487876]],\n",
            "\n",
            "        [[0.9637833834]],\n",
            "\n",
            "        [[0.9672523141]]])\n",
            "avg pooling output= tensor([[[0.9938514233, 0.9965384007, 0.9534098506, 0.9482126236, 0.9866490960,\n",
            "          0.9996857047, 0.9972437620, 0.9986917973, 0.9967099428, 0.9970217943],\n",
            "         [0.9971296787, 0.9959545135, 0.9829770327, 0.9780254364, 0.9917511344,\n",
            "          0.9996210933, 0.9995211363, 0.9991723299, 0.9990736842, 0.9989347458],\n",
            "         [0.9981204271, 0.9987933040, 0.9986392260, 0.9988882542, 0.9990505576,\n",
            "          0.9994976521, 0.9990847111, 0.9993624091, 0.9999542236, 0.9994866848],\n",
            "         [0.9900511503, 0.9979474545, 0.9954687953, 0.9989968538, 0.9993458986,\n",
            "          0.9998028278, 0.9997441769, 0.9998099208, 0.9997220635, 0.9994498491],\n",
            "         [0.9932183027, 0.9877082109, 0.9811509252, 0.9935768843, 0.9953954220,\n",
            "          0.9986281991, 0.9981501698, 0.9947039485, 0.9964982271, 0.9984667301],\n",
            "         [0.9807510376, 0.9942966104, 0.9945369363, 0.9914569855, 0.9905673265,\n",
            "          0.9952151179, 0.9888113737, 0.9768208265, 0.9850392938, 0.9827075601],\n",
            "         [0.9818050861, 0.9851474762, 0.9899109602, 0.9816508889, 0.9750887752,\n",
            "          0.9818247557, 0.9719825387, 0.9555579424, 0.9720765352, 0.9693849087],\n",
            "         [0.9985494614, 0.9930450916, 0.9869504571, 0.9515510201, 0.9543725252,\n",
            "          0.9601773024, 0.9648566842, 0.9672858715, 0.9730985165, 0.9816912413],\n",
            "         [0.9996363521, 0.9988458157, 0.9661753178, 0.8662841320, 0.8726626039,\n",
            "          0.8564500809, 0.8648383617, 0.8429536819, 0.9329386950, 0.9919891357],\n",
            "         [0.9997655153, 0.9993889928, 0.9428212643, 0.7752907276, 0.7674431205,\n",
            "          0.7809264064, 0.8029863834, 0.8435199857, 0.9358794093, 0.9879133701]],\n",
            "\n",
            "        [[0.9934402108, 0.9962611794, 0.9514912367, 0.9468837380, 0.9851544499,\n",
            "          0.9996651411, 0.9973851442, 0.9990572333, 0.9971160889, 0.9977180958],\n",
            "         [0.9978412986, 0.9963513613, 0.9863007069, 0.9795095921, 0.9929236174,\n",
            "          0.9996365309, 0.9993817806, 0.9987290502, 0.9987843037, 0.9988278151],\n",
            "         [0.9983990788, 0.9990751743, 0.9990063906, 0.9991645813, 0.9993255138,\n",
            "          0.9996227622, 0.9993461967, 0.9994598031, 0.9999468327, 0.9995036721],\n",
            "         [0.9908753633, 0.9979854226, 0.9961692095, 0.9991065264, 0.9994331002,\n",
            "          0.9998522997, 0.9997713566, 0.9998175502, 0.9997655153, 0.9994288683],\n",
            "         [0.9944930673, 0.9863703251, 0.9821648002, 0.9946993589, 0.9954755306,\n",
            "          0.9984050393, 0.9982078075, 0.9950754642, 0.9966856837, 0.9982843399],\n",
            "         [0.9764466882, 0.9958602190, 0.9950649738, 0.9926950932, 0.9919831753,\n",
            "          0.9955679774, 0.9892586470, 0.9796320796, 0.9857976437, 0.9811935425],\n",
            "         [0.9835089445, 0.9834476113, 0.9891095757, 0.9847323298, 0.9768119454,\n",
            "          0.9836819172, 0.9727203846, 0.9536266327, 0.9733244777, 0.9716167450],\n",
            "         [0.9992194772, 0.9941241145, 0.9856662750, 0.9580675960, 0.9599643350,\n",
            "          0.9641193748, 0.9683575034, 0.9701649547, 0.9744250774, 0.9842992425],\n",
            "         [0.9997705817, 0.9991595149, 0.9579613805, 0.8667045236, 0.8807991743,\n",
            "          0.8572676182, 0.8682002425, 0.8448607922, 0.9403063655, 0.9943199158],\n",
            "         [0.9998505712, 0.9996179938, 0.9430357814, 0.7796483636, 0.7727801204,\n",
            "          0.7922239304, 0.8127251267, 0.8590978980, 0.9468754530, 0.9904629588]],\n",
            "\n",
            "        [[0.9939377904, 0.9956753850, 0.9515018463, 0.9484142661, 0.9868966341,\n",
            "          0.9996681213, 0.9963648915, 0.9986642003, 0.9962183833, 0.9968158007],\n",
            "         [0.9969292879, 0.9943178892, 0.9805022478, 0.9723050594, 0.9913174510,\n",
            "          0.9994708300, 0.9991242886, 0.9989384413, 0.9987360835, 0.9989239573],\n",
            "         [0.9983572364, 0.9988157749, 0.9987494349, 0.9990565777, 0.9992189407,\n",
            "          0.9995246530, 0.9988861084, 0.9992283583, 0.9999277592, 0.9993134737],\n",
            "         [0.9915726781, 0.9982704520, 0.9970357418, 0.9993391037, 0.9995092750,\n",
            "          0.9998524785, 0.9997534156, 0.9998129606, 0.9997306466, 0.9992836714],\n",
            "         [0.9939791560, 0.9848636985, 0.9855514169, 0.9951068163, 0.9951182604,\n",
            "          0.9985063076, 0.9983346462, 0.9957082272, 0.9971637726, 0.9986682534],\n",
            "         [0.9822070003, 0.9954537153, 0.9944937229, 0.9926626682, 0.9910195470,\n",
            "          0.9960412979, 0.9909721017, 0.9850809574, 0.9893397093, 0.9852141142],\n",
            "         [0.9782059789, 0.9870198369, 0.9886510372, 0.9855564833, 0.9778854847,\n",
            "          0.9854710698, 0.9743419290, 0.9540627599, 0.9692946672, 0.9647740126],\n",
            "         [0.9983800054, 0.9923784733, 0.9833357930, 0.9628840685, 0.9604159594,\n",
            "          0.9650263190, 0.9685491920, 0.9689110518, 0.9748058319, 0.9828196764],\n",
            "         [0.9996476769, 0.9988322854, 0.9581351876, 0.9007536769, 0.9031498432,\n",
            "          0.8841227293, 0.8900767565, 0.8634462357, 0.9374930859, 0.9928811193],\n",
            "         [0.9997701645, 0.9993455410, 0.9283224940, 0.7628139853, 0.7782739401,\n",
            "          0.7931990623, 0.8103347421, 0.8486329913, 0.9411118627, 0.9900966287]],\n",
            "\n",
            "        [[0.9886996150, 0.9921357632, 0.9317122698, 0.9249293208, 0.9772754312,\n",
            "          0.9989471436, 0.9936042428, 0.9967618585, 0.9922659993, 0.9926425219],\n",
            "         [0.9943336844, 0.9916442037, 0.9740735292, 0.9637247920, 0.9857149124,\n",
            "          0.9986568093, 0.9984654188, 0.9978739619, 0.9974237084, 0.9969046712],\n",
            "         [0.9968046546, 0.9978680015, 0.9978532791, 0.9983306527, 0.9984238744,\n",
            "          0.9990175962, 0.9981586933, 0.9984999895, 0.9998033047, 0.9983444214],\n",
            "         [0.9873387218, 0.9963557124, 0.9950093031, 0.9983837605, 0.9987218380,\n",
            "          0.9995163679, 0.9993827343, 0.9995098114, 0.9993050694, 0.9984868169],\n",
            "         [0.9909182787, 0.9828838706, 0.9776284695, 0.9912689924, 0.9913852215,\n",
            "          0.9973080754, 0.9971370697, 0.9936193824, 0.9952103496, 0.9974092841],\n",
            "         [0.9763713479, 0.9921162724, 0.9904854894, 0.9882385731, 0.9864388704,\n",
            "          0.9924129844, 0.9860039949, 0.9728175402, 0.9786826372, 0.9746884108],\n",
            "         [0.9763509035, 0.9808180332, 0.9854954481, 0.9783780575, 0.9684241414,\n",
            "          0.9756851196, 0.9628279805, 0.9353271127, 0.9560598731, 0.9561110735],\n",
            "         [0.9976164699, 0.9899095893, 0.9817895889, 0.9527451396, 0.9535812736,\n",
            "          0.9556286931, 0.9599406123, 0.9574981332, 0.9626882076, 0.9774460196],\n",
            "         [0.9991884232, 0.9977163672, 0.9575284123, 0.8722768426, 0.8819789886,\n",
            "          0.8630211353, 0.8671510220, 0.8399282694, 0.9244495034, 0.9894940853],\n",
            "         [0.9994268417, 0.9987154007, 0.9336600900, 0.7668706179, 0.7665738463,\n",
            "          0.7770813704, 0.7978881001, 0.8391659856, 0.9320313931, 0.9855045676]],\n",
            "\n",
            "        [[0.9867875576, 0.9920054674, 0.9286389947, 0.9205041528, 0.9755799770,\n",
            "          0.9989746809, 0.9941790104, 0.9970763326, 0.9929573536, 0.9935410619],\n",
            "         [0.9937595725, 0.9917998910, 0.9741908312, 0.9643305540, 0.9865158796,\n",
            "          0.9988420010, 0.9986501336, 0.9980076551, 0.9978704453, 0.9973363876],\n",
            "         [0.9951927662, 0.9967231750, 0.9964234829, 0.9970524907, 0.9974797368,\n",
            "          0.9985520840, 0.9979579449, 0.9986075163, 0.9998357296, 0.9986336827],\n",
            "         [0.9785013199, 0.9941632152, 0.9888069630, 0.9974043369, 0.9980805516,\n",
            "          0.9993216395, 0.9991143346, 0.9993621111, 0.9991191030, 0.9985114336],\n",
            "         [0.9858237505, 0.9798811674, 0.9583464861, 0.9862285256, 0.9895026088,\n",
            "          0.9961420894, 0.9948908687, 0.9880608320, 0.9916753769, 0.9959198833],\n",
            "         [0.9575797319, 0.9894353151, 0.9874973297, 0.9824509025, 0.9816867113,\n",
            "          0.9903017879, 0.9778724313, 0.9592200518, 0.9712992907, 0.9663019180],\n",
            "         [0.9674021602, 0.9707947969, 0.9795973301, 0.9666012526, 0.9567879438,\n",
            "          0.9657691121, 0.9556113482, 0.9287996292, 0.9532807469, 0.9511826634],\n",
            "         [0.9964627028, 0.9875553846, 0.9757345915, 0.9200397134, 0.9310356975,\n",
            "          0.9377043843, 0.9440947771, 0.9509473443, 0.9548566341, 0.9675741196],\n",
            "         [0.9986922145, 0.9969735742, 0.9488615394, 0.8069618344, 0.8319327831,\n",
            "          0.8086680174, 0.8212767839, 0.7974776030, 0.9000977278, 0.9844173789],\n",
            "         [0.9991030097, 0.9981310368, 0.9273961186, 0.7337011695, 0.7229151130,\n",
            "          0.7423428297, 0.7613369823, 0.8073902130, 0.9031573534, 0.9744073153]],\n",
            "\n",
            "        [[0.9943978786, 0.9961162210, 0.9541421533, 0.9508392811, 0.9885327816,\n",
            "          0.9997811913, 0.9977312088, 0.9992461801, 0.9972937703, 0.9978154302],\n",
            "         [0.9976561069, 0.9953204393, 0.9874139428, 0.9800879955, 0.9940804243,\n",
            "          0.9997231364, 0.9994557500, 0.9993400574, 0.9992592931, 0.9993865490],\n",
            "         [0.9978256226, 0.9985520840, 0.9981765747, 0.9985541105, 0.9988333583,\n",
            "          0.9994314909, 0.9990553260, 0.9995017648, 0.9999594092, 0.9996897578],\n",
            "         [0.9868257046, 0.9974358678, 0.9931452274, 0.9988663197, 0.9993591309,\n",
            "          0.9998410344, 0.9997126460, 0.9998039603, 0.9997465611, 0.9995587468],\n",
            "         [0.9917330146, 0.9849101305, 0.9803104401, 0.9920313358, 0.9951360226,\n",
            "          0.9985159636, 0.9971811771, 0.9917941689, 0.9951012731, 0.9977648258],\n",
            "         [0.9740956426, 0.9934832454, 0.9942176342, 0.9893450141, 0.9883635640,\n",
            "          0.9951095581, 0.9854774475, 0.9737477899, 0.9846023917, 0.9819573164],\n",
            "         [0.9763346910, 0.9814484715, 0.9873421788, 0.9779925942, 0.9704053402,\n",
            "          0.9815927148, 0.9685084224, 0.9588023424, 0.9739427567, 0.9715217948],\n",
            "         [0.9979141951, 0.9917639494, 0.9831110835, 0.9342422485, 0.9368640184,\n",
            "          0.9479575753, 0.9557497501, 0.9623504281, 0.9715760350, 0.9807370305],\n",
            "         [0.9995229244, 0.9985414147, 0.9575045109, 0.8389236927, 0.8418771029,\n",
            "          0.8291676044, 0.8383280635, 0.8238151073, 0.9258453846, 0.9920067191],\n",
            "         [0.9997128248, 0.9991501570, 0.9285172224, 0.7551262975, 0.7440651655,\n",
            "          0.7668951750, 0.7858073711, 0.8332266808, 0.9267103672, 0.9836067557]],\n",
            "\n",
            "        [[0.9883416295, 0.9924628139, 0.9326517582, 0.9263362885, 0.9781540632,\n",
            "          0.9991624355, 0.9943746924, 0.9973599911, 0.9934402108, 0.9940621853],\n",
            "         [0.9946993589, 0.9912965298, 0.9732152224, 0.9662321806, 0.9869859219,\n",
            "          0.9988813400, 0.9984730482, 0.9980196357, 0.9976798296, 0.9973824620],\n",
            "         [0.9963586330, 0.9975886941, 0.9973553419, 0.9978072047, 0.9981334209,\n",
            "          0.9988589883, 0.9980046749, 0.9986125231, 0.9998250604, 0.9984385371],\n",
            "         [0.9852302074, 0.9957637787, 0.9930744171, 0.9980286360, 0.9985084534,\n",
            "          0.9994943142, 0.9993302822, 0.9994676113, 0.9992686510, 0.9984200001],\n",
            "         [0.9896771312, 0.9773183465, 0.9735280275, 0.9893161058, 0.9907672405,\n",
            "          0.9970104694, 0.9964371920, 0.9911651611, 0.9938337803, 0.9971050620],\n",
            "         [0.9710190296, 0.9913361669, 0.9905128479, 0.9863808751, 0.9846323729,\n",
            "          0.9919696450, 0.9828617573, 0.9679795504, 0.9766171575, 0.9713518620],\n",
            "         [0.9700573683, 0.9787881374, 0.9837411046, 0.9742924571, 0.9623663425,\n",
            "          0.9723572135, 0.9578914642, 0.9335944057, 0.9567844868, 0.9534308314],\n",
            "         [0.9974057078, 0.9882986546, 0.9780525565, 0.9424228668, 0.9413490295,\n",
            "          0.9482165575, 0.9530404210, 0.9538924098, 0.9601287842, 0.9728794098],\n",
            "         [0.9991924763, 0.9976722002, 0.9477354884, 0.8542292118, 0.8561170101,\n",
            "          0.8370371461, 0.8462476730, 0.8203535080, 0.9169875383, 0.9885492325],\n",
            "         [0.9994350076, 0.9986737370, 0.9232122898, 0.7446549535, 0.7462691665,\n",
            "          0.7592256665, 0.7785683870, 0.8233249187, 0.9215686321, 0.9827018380]],\n",
            "\n",
            "        [[0.9884183407, 0.9915304184, 0.9296296239, 0.9259383082, 0.9785473347,\n",
            "          0.9991249442, 0.9933758974, 0.9974864125, 0.9928842187, 0.9941621423],\n",
            "         [0.9951310754, 0.9903994799, 0.9749739170, 0.9636011124, 0.9870885015,\n",
            "          0.9986960292, 0.9979306459, 0.9973952770, 0.9967839122, 0.9969857335],\n",
            "         [0.9970185161, 0.9980786443, 0.9980814457, 0.9984772205, 0.9986835122,\n",
            "          0.9991426468, 0.9982883930, 0.9986271262, 0.9997637272, 0.9981415272],\n",
            "         [0.9881061912, 0.9963057637, 0.9954388142, 0.9985691905, 0.9987705946,\n",
            "          0.9995990396, 0.9994204044, 0.9995160699, 0.9993445277, 0.9982258677],\n",
            "         [0.9913384914, 0.9769475460, 0.9797871709, 0.9919117689, 0.9914601445,\n",
            "          0.9972119927, 0.9970760345, 0.9934113026, 0.9954144359, 0.9975969791],\n",
            "         [0.9729991555, 0.9933422804, 0.9905363917, 0.9892143607, 0.9871317744,\n",
            "          0.9932015538, 0.9851575494, 0.9752354026, 0.9798979163, 0.9735915065],\n",
            "         [0.9709960222, 0.9810909629, 0.9830244780, 0.9801375866, 0.9674710035,\n",
            "          0.9769958854, 0.9611855745, 0.9341752529, 0.9565522671, 0.9543236494],\n",
            "         [0.9979602098, 0.9890717268, 0.9759685993, 0.9567824602, 0.9543359280,\n",
            "          0.9582894444, 0.9607281089, 0.9589858651, 0.9635444283, 0.9775891900],\n",
            "         [0.9993923903, 0.9979442954, 0.9405894876, 0.8785138726, 0.8822716475,\n",
            "          0.8618097901, 0.8679620028, 0.8408612013, 0.9294898510, 0.9915245771],\n",
            "         [0.9995719194, 0.9989454746, 0.9199221134, 0.7534859776, 0.7634203434,\n",
            "          0.7765796185, 0.7958547473, 0.8428214192, 0.9372262955, 0.9876944423]]])\n",
            "max pooling output= tensor([[[0.9978395104, 0.9991998672, 0.9841291904, 0.9740279317, 0.9995280504,\n",
            "          0.9998772740, 0.9998784065, 0.9999164939, 0.9997669458, 0.9987712502],\n",
            "         [0.9988554120, 0.9989697933, 0.9991597533, 0.9987990260, 0.9995507002,\n",
            "          0.9998513460, 0.9999447465, 0.9999728203, 0.9999875426, 0.9994750619],\n",
            "         [0.9987580776, 0.9991179109, 0.9994438887, 0.9993881583, 0.9993468523,\n",
            "          0.9996382594, 0.9996917844, 0.9999692440, 0.9999955893, 0.9998187423],\n",
            "         [0.9960249066, 0.9986760616, 0.9983277321, 0.9996712804, 0.9995465875,\n",
            "          0.9999051690, 0.9998373389, 0.9998785853, 0.9997932911, 0.9997954965],\n",
            "         [0.9969872832, 0.9978869557, 0.9913699031, 0.9970433712, 0.9991578460,\n",
            "          0.9998105168, 0.9995266199, 0.9988562465, 0.9997271299, 0.9997490644],\n",
            "         [0.9953016043, 0.9992782474, 0.9994344711, 0.9936511517, 0.9937276840,\n",
            "          0.9983084798, 0.9971182942, 0.9829571843, 0.9908360243, 0.9940333366],\n",
            "         [0.9991794825, 0.9993185997, 0.9994031191, 0.9870460033, 0.9833896160,\n",
            "          0.9914695621, 0.9903206825, 0.9718653560, 0.9803453088, 0.9852618575],\n",
            "         [0.9995591640, 0.9985676408, 0.9990924597, 0.9762426615, 0.9750302434,\n",
            "          0.9866935611, 0.9802997708, 0.9757514000, 0.9829665422, 0.9975654483],\n",
            "         [0.9997517467, 0.9995694160, 0.9980713725, 0.9252853990, 0.9185851812,\n",
            "          0.9095245600, 0.9152176380, 0.8918443918, 0.9642243385, 0.9986822009],\n",
            "         [0.9998308420, 0.9997394085, 0.9976949692, 0.8857055902, 0.7872025371,\n",
            "          0.7968535423, 0.8263496757, 0.9074662924, 0.9684724808, 0.9966350198]],\n",
            "\n",
            "        [[0.9976077080, 0.9989443421, 0.9848753214, 0.9738624692, 0.9995716810,\n",
            "          0.9999131560, 0.9999178648, 0.9999590516, 0.9998329878, 0.9988049865],\n",
            "         [0.9989547729, 0.9992557764, 0.9995168447, 0.9993411899, 0.9996704459,\n",
            "          0.9998930693, 0.9999591112, 0.9999845624, 0.9999924898, 0.9995190501],\n",
            "         [0.9990483522, 0.9994556308, 0.9995656610, 0.9994713664, 0.9995928407,\n",
            "          0.9997560978, 0.9998143911, 0.9999741316, 0.9999960661, 0.9998028874],\n",
            "         [0.9967483878, 0.9989108443, 0.9988335967, 0.9997497201, 0.9996843934,\n",
            "          0.9999386668, 0.9998780489, 0.9999164343, 0.9998501539, 0.9998736382],\n",
            "         [0.9974985123, 0.9985945821, 0.9932584167, 0.9964196682, 0.9988875985,\n",
            "          0.9998528957, 0.9995696545, 0.9988151193, 0.9997302294, 0.9997938871],\n",
            "         [0.9968599677, 0.9995769858, 0.9996814132, 0.9951509833, 0.9950593710,\n",
            "          0.9990209341, 0.9977202415, 0.9849184155, 0.9918512702, 0.9936610460],\n",
            "         [0.9995500445, 0.9995992780, 0.9995952249, 0.9885887504, 0.9849603176,\n",
            "          0.9908525944, 0.9887096882, 0.9707700014, 0.9831443429, 0.9892830253],\n",
            "         [0.9997166395, 0.9986800551, 0.9994871020, 0.9795349836, 0.9794144630,\n",
            "          0.9870029092, 0.9793147445, 0.9803786874, 0.9855353236, 0.9983693957],\n",
            "         [0.9998358488, 0.9997263551, 0.9986374974, 0.9379460216, 0.9286226630,\n",
            "          0.9132097960, 0.9163737297, 0.9014723301, 0.9711509943, 0.9991799593],\n",
            "         [0.9998902082, 0.9998340607, 0.9989328384, 0.9094930291, 0.8061422706,\n",
            "          0.8159947395, 0.8448292017, 0.9247006774, 0.9769648314, 0.9972909093]],\n",
            "\n",
            "        [[0.9978998303, 0.9990490079, 0.9824018478, 0.9735082388, 0.9996487498,\n",
            "          0.9998655319, 0.9998089075, 0.9999175072, 0.9996298552, 0.9987338185],\n",
            "         [0.9988794923, 0.9991189837, 0.9988924265, 0.9980471730, 0.9994295239,\n",
            "          0.9998820424, 0.9999434352, 0.9999769926, 0.9999823570, 0.9994457960],\n",
            "         [0.9987787604, 0.9993010759, 0.9993412495, 0.9993401170, 0.9995099306,\n",
            "          0.9997600913, 0.9997671843, 0.9999750257, 0.9999945760, 0.9997607470],\n",
            "         [0.9971992373, 0.9989171624, 0.9986371398, 0.9997378588, 0.9996605515,\n",
            "          0.9999108315, 0.9998788834, 0.9999005795, 0.9998281002, 0.9998254180],\n",
            "         [0.9977185130, 0.9984089136, 0.9940867424, 0.9976549149, 0.9993736744,\n",
            "          0.9997888207, 0.9995716214, 0.9989899397, 0.9997211695, 0.9997409582],\n",
            "         [0.9969497323, 0.9995727539, 0.9992289543, 0.9949648380, 0.9941164851,\n",
            "          0.9985789657, 0.9966050386, 0.9879857898, 0.9931991100, 0.9963548183],\n",
            "         [0.9991280437, 0.9996156693, 0.9991511703, 0.9891337752, 0.9860866070,\n",
            "          0.9919967055, 0.9912627935, 0.9739639759, 0.9775735140, 0.9861379862],\n",
            "         [0.9995381236, 0.9989528060, 0.9991052151, 0.9804214835, 0.9770267606,\n",
            "          0.9859350324, 0.9747646451, 0.9746587873, 0.9825465083, 0.9985005856],\n",
            "         [0.9997430444, 0.9995795488, 0.9982604980, 0.9436688423, 0.9403938055,\n",
            "          0.9303934574, 0.9333832860, 0.9216322303, 0.9721500874, 0.9989234209],\n",
            "         [0.9998296499, 0.9997287393, 0.9971851110, 0.8572168946, 0.8098978400,\n",
            "          0.8158180118, 0.8259555697, 0.9101725817, 0.9727191329, 0.9974206686]],\n",
            "\n",
            "        [[0.9947201610, 0.9978646040, 0.9728115797, 0.9563979506, 0.9984495640,\n",
            "          0.9995006919, 0.9994991422, 0.9996455312, 0.9987968206, 0.9965588450],\n",
            "         [0.9975947142, 0.9981548786, 0.9977746010, 0.9972484708, 0.9985440373,\n",
            "          0.9993909597, 0.9997259378, 0.9998596907, 0.9999310374, 0.9982632399],\n",
            "         [0.9975637794, 0.9984647036, 0.9988194108, 0.9988306761, 0.9987701178,\n",
            "          0.9992795587, 0.9993346334, 0.9998255968, 0.9999674559, 0.9993096590],\n",
            "         [0.9950090647, 0.9977807999, 0.9975674748, 0.9992533922, 0.9990845919,\n",
            "          0.9996387959, 0.9995758533, 0.9996597767, 0.9994541407, 0.9993560910],\n",
            "         [0.9954707026, 0.9957004189, 0.9900119305, 0.9947360754, 0.9977658987,\n",
            "          0.9994809628, 0.9989505410, 0.9979420304, 0.9992503524, 0.9992924929],\n",
            "         [0.9936628938, 0.9982343912, 0.9978689551, 0.9906319976, 0.9897652268,\n",
            "          0.9966147542, 0.9946169853, 0.9827145934, 0.9884997010, 0.9900320172],\n",
            "         [0.9984109402, 0.9982129335, 0.9979776144, 0.9837082028, 0.9788917303,\n",
            "          0.9870307446, 0.9865993261, 0.9592211246, 0.9684249759, 0.9818513989],\n",
            "         [0.9990425706, 0.9967753291, 0.9974545836, 0.9736763835, 0.9710351825,\n",
            "          0.9791592360, 0.9755400419, 0.9653870463, 0.9720155001, 0.9958971143],\n",
            "         [0.9993993640, 0.9990434051, 0.9952700734, 0.9340534210, 0.9292579293,\n",
            "          0.9116249084, 0.9171277881, 0.8896096945, 0.9597110152, 0.9973740578],\n",
            "         [0.9995509386, 0.9993556738, 0.9962280989, 0.8722733259, 0.7818187475,\n",
            "          0.7907054424, 0.8216094971, 0.9004233479, 0.9655397534, 0.9951843023]],\n",
            "\n",
            "        [[0.9948059320, 0.9975693822, 0.9764587283, 0.9555201530, 0.9984107614,\n",
            "          0.9995523095, 0.9996378422, 0.9997100830, 0.9992276430, 0.9965278506],\n",
            "         [0.9969664812, 0.9975760579, 0.9982326627, 0.9979619384, 0.9987074137,\n",
            "          0.9995098710, 0.9998384118, 0.9998757243, 0.9999559522, 0.9988954067],\n",
            "         [0.9968240857, 0.9976535439, 0.9984132051, 0.9983379245, 0.9982308745,\n",
            "          0.9990565777, 0.9991436601, 0.9998599887, 0.9999771118, 0.9993898869],\n",
            "         [0.9911757112, 0.9962064028, 0.9953202009, 0.9991007447, 0.9987434149,\n",
            "          0.9996125102, 0.9994946122, 0.9996209145, 0.9993262887, 0.9993779659],\n",
            "         [0.9931983948, 0.9942615032, 0.9811379910, 0.9926526546, 0.9973797798,\n",
            "          0.9993109107, 0.9983506203, 0.9968091249, 0.9991388917, 0.9994075298],\n",
            "         [0.9895281196, 0.9982516170, 0.9982835650, 0.9868083000, 0.9883609414,\n",
            "          0.9963909984, 0.9921505451, 0.9671315551, 0.9804539084, 0.9862531424],\n",
            "         [0.9975878596, 0.9982718825, 0.9982883334, 0.9747285843, 0.9688450098,\n",
            "          0.9797815084, 0.9802156687, 0.9472592473, 0.9684566855, 0.9754924178],\n",
            "         [0.9983179569, 0.9964861870, 0.9976024628, 0.9602536559, 0.9608823061,\n",
            "          0.9743875265, 0.9668238759, 0.9644653797, 0.9732414484, 0.9927780032],\n",
            "         [0.9990475774, 0.9984595180, 0.9947055578, 0.8894430995, 0.8824599385,\n",
            "          0.8682084084, 0.8738145828, 0.8507231474, 0.9424577951, 0.9961327314],\n",
            "         [0.9993281364, 0.9989680648, 0.9954746962, 0.8583356738, 0.7557534575,\n",
            "          0.7585905790, 0.7926628590, 0.8768172264, 0.9446857572, 0.9909088612]],\n",
            "\n",
            "        [[0.9979671240, 0.9993299842, 0.9836552739, 0.9762495160, 0.9996961951,\n",
            "          0.9999348521, 0.9999256730, 0.9999650717, 0.9998073578, 0.9991959333],\n",
            "         [0.9987340569, 0.9991255403, 0.9993377924, 0.9989963770, 0.9995665550,\n",
            "          0.9999296665, 0.9999753833, 0.9999902844, 0.9999954104, 0.9997238517],\n",
            "         [0.9987945557, 0.9991277456, 0.9992670417, 0.9991359115, 0.9992396235,\n",
            "          0.9997048974, 0.9997780323, 0.9999878407, 0.9999981523, 0.9998721480],\n",
            "         [0.9960438609, 0.9985985756, 0.9973734617, 0.9997277260, 0.9996539950,\n",
            "          0.9999244213, 0.9998757839, 0.9999161959, 0.9998632669, 0.9998496771],\n",
            "         [0.9970307350, 0.9979444742, 0.9908213019, 0.9961482286, 0.9993218780,\n",
            "          0.9998534322, 0.9994439483, 0.9983681440, 0.9997156262, 0.9998551607],\n",
            "         [0.9941082597, 0.9996542335, 0.9995261431, 0.9928639531, 0.9934261441,\n",
            "          0.9987539053, 0.9967005253, 0.9792518020, 0.9895445108, 0.9934541583],\n",
            "         [0.9988214970, 0.9995955825, 0.9994210601, 0.9842402339, 0.9791552424,\n",
            "          0.9884743094, 0.9861174822, 0.9732441902, 0.9822893143, 0.9872358441],\n",
            "         [0.9993556738, 0.9990319014, 0.9993432760, 0.9679690003, 0.9667104483,\n",
            "          0.9842530489, 0.9754133224, 0.9789568186, 0.9832368493, 0.9980986714],\n",
            "         [0.9996683002, 0.9994107485, 0.9982388616, 0.8984080553, 0.8896161318,\n",
            "          0.8792048097, 0.8843958974, 0.8819281459, 0.9615498185, 0.9986940026],\n",
            "         [0.9997999668, 0.9996514320, 0.9971821308, 0.8678109050, 0.7700489759,\n",
            "          0.7847135067, 0.8134178519, 0.9003523588, 0.9608353972, 0.9954885840]],\n",
            "\n",
            "        [[0.9946865439, 0.9978942275, 0.9736766815, 0.9568015337, 0.9988380671,\n",
            "          0.9996123910, 0.9995788336, 0.9997400641, 0.9992749095, 0.9973577261],\n",
            "         [0.9977881312, 0.9976726174, 0.9981660843, 0.9973219633, 0.9988094568,\n",
            "          0.9995877743, 0.9998457432, 0.9998874068, 0.9999533892, 0.9986814260],\n",
            "         [0.9973369241, 0.9981715679, 0.9987388253, 0.9986889362, 0.9986030459,\n",
            "          0.9992430210, 0.9992467165, 0.9998955131, 0.9999781251, 0.9993893504],\n",
            "         [0.9931647182, 0.9974334836, 0.9970175028, 0.9991550446, 0.9988207817,\n",
            "          0.9996716380, 0.9995937943, 0.9996832609, 0.9994657040, 0.9994822145],\n",
            "         [0.9944929481, 0.9955502748, 0.9876797199, 0.9939580560, 0.9982984662,\n",
            "          0.9993571639, 0.9989339709, 0.9974654913, 0.9992161393, 0.9993484616],\n",
            "         [0.9934118390, 0.9984431863, 0.9982988834, 0.9897835851, 0.9892222285,\n",
            "          0.9958701730, 0.9944580793, 0.9762921333, 0.9851810336, 0.9909793735],\n",
            "         [0.9984446764, 0.9985365868, 0.9981509447, 0.9799210429, 0.9736477137,\n",
            "          0.9856553674, 0.9857074618, 0.9549515843, 0.9702821970, 0.9792553186],\n",
            "         [0.9990161061, 0.9971929193, 0.9976785779, 0.9676438570, 0.9637559056,\n",
            "          0.9782801867, 0.9681072831, 0.9639521241, 0.9739026427, 0.9962130189],\n",
            "         [0.9993995428, 0.9990850687, 0.9956290126, 0.9143721461, 0.9078792334,\n",
            "          0.8937465549, 0.8985341191, 0.8748098016, 0.9578942657, 0.9974446893],\n",
            "         [0.9995721579, 0.9993658662, 0.9955824614, 0.8561974168, 0.7640249729,\n",
            "          0.7730731368, 0.8054000735, 0.8893639445, 0.9588373303, 0.9943032265]],\n",
            "\n",
            "        [[0.9950474501, 0.9977713227, 0.9692603350, 0.9583536386, 0.9990389943,\n",
            "          0.9996621609, 0.9995214343, 0.9997731447, 0.9989258647, 0.9975598454],\n",
            "         [0.9978846908, 0.9982889295, 0.9982035160, 0.9972357750, 0.9989554882,\n",
            "          0.9996136427, 0.9997965693, 0.9999204278, 0.9999381900, 0.9983110428],\n",
            "         [0.9977782369, 0.9985216856, 0.9990096092, 0.9988846779, 0.9989810586,\n",
            "          0.9994430542, 0.9994215369, 0.9999011159, 0.9999716282, 0.9992409348],\n",
            "         [0.9954598546, 0.9981766343, 0.9979164600, 0.9992451668, 0.9991099834,\n",
            "          0.9997211695, 0.9996370077, 0.9996824861, 0.9995427132, 0.9995178580],\n",
            "         [0.9959579706, 0.9969903231, 0.9916230440, 0.9947479367, 0.9980888367,\n",
            "          0.9994411469, 0.9991169572, 0.9979873300, 0.9992307425, 0.9993569851],\n",
            "         [0.9957079291, 0.9990219474, 0.9982239604, 0.9919520020, 0.9907687306,\n",
            "          0.9967750311, 0.9945162535, 0.9838111401, 0.9891956449, 0.9927332997],\n",
            "         [0.9987937808, 0.9990246892, 0.9980742335, 0.9839728475, 0.9782828093,\n",
            "          0.9884667993, 0.9869325161, 0.9598642588, 0.9704024792, 0.9833671451],\n",
            "         [0.9992798567, 0.9977363348, 0.9980929494, 0.9750930071, 0.9714368582,\n",
            "          0.9805027246, 0.9689231515, 0.9670478702, 0.9742664695, 0.9975456595],\n",
            "         [0.9995354414, 0.9993010759, 0.9965550900, 0.9366589189, 0.9294109941,\n",
            "          0.9175772071, 0.9210913777, 0.9012700915, 0.9660444260, 0.9982953668],\n",
            "         [0.9996614456, 0.9995105863, 0.9965181351, 0.8618038893, 0.7836449146,\n",
            "          0.7923536301, 0.8228176832, 0.9066314101, 0.9699769616, 0.9961190224]]])\n"
          ]
        }
      ],
      "source": [
        "#testng pooling layer function\n",
        "inp =  conv_layer_output\n",
        "stride=torch.tensor([3,3])\n",
        "\n",
        "#printing input activation map\n",
        "print('input activation map=',inp)\n",
        "\n",
        "pooling_output=pooling_layer_function(inp,stride,avg_pool)\n",
        "#print pooled outputs\n",
        "print('global pooling output=',pooling_layer_function(inp))\n",
        "print('avg pooling output=',pooling_layer_function(inp,stride,avg_pool))\n",
        "print('max pooling output=',pooling_layer_function(inp,stride,max_pool))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "f2ZfIKRIXnFM"
      },
      "source": [
        "**QUESTION 5**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<Font size=2>**FLATTENING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "id": "3OOTu-G3OpaN"
      },
      "outputs": [],
      "source": [
        "#it reshapes the matrix into a vector . Using weight matrix it converts vector to desired length\n",
        "def flattening(input,output_vector_length,weight_matrix=None):\n",
        "  input=input.reshape(-1)\n",
        "  #randomly initializing weight matrix if it is not given\n",
        "  if weight_matrix==None:\n",
        "    weight_matrix=torch.rand([input.shape[0],output_vector_length])\n",
        "  return weight_matrix.T@input"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<Font size=2>**Printing outputs**\\\n",
        "prints input,flattened output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rkby-C0FPALO",
        "outputId": "1bd06c07-a34e-41ad-cf53-af7a6c9eb9d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input= tensor([[[0.9938514233, 0.9965384007, 0.9534098506, 0.9482126236, 0.9866490960,\n",
            "          0.9996857047, 0.9972437620, 0.9986917973, 0.9967099428, 0.9970217943],\n",
            "         [0.9971296787, 0.9959545135, 0.9829770327, 0.9780254364, 0.9917511344,\n",
            "          0.9996210933, 0.9995211363, 0.9991723299, 0.9990736842, 0.9989347458],\n",
            "         [0.9981204271, 0.9987933040, 0.9986392260, 0.9988882542, 0.9990505576,\n",
            "          0.9994976521, 0.9990847111, 0.9993624091, 0.9999542236, 0.9994866848],\n",
            "         [0.9900511503, 0.9979474545, 0.9954687953, 0.9989968538, 0.9993458986,\n",
            "          0.9998028278, 0.9997441769, 0.9998099208, 0.9997220635, 0.9994498491],\n",
            "         [0.9932183027, 0.9877082109, 0.9811509252, 0.9935768843, 0.9953954220,\n",
            "          0.9986281991, 0.9981501698, 0.9947039485, 0.9964982271, 0.9984667301],\n",
            "         [0.9807510376, 0.9942966104, 0.9945369363, 0.9914569855, 0.9905673265,\n",
            "          0.9952151179, 0.9888113737, 0.9768208265, 0.9850392938, 0.9827075601],\n",
            "         [0.9818050861, 0.9851474762, 0.9899109602, 0.9816508889, 0.9750887752,\n",
            "          0.9818247557, 0.9719825387, 0.9555579424, 0.9720765352, 0.9693849087],\n",
            "         [0.9985494614, 0.9930450916, 0.9869504571, 0.9515510201, 0.9543725252,\n",
            "          0.9601773024, 0.9648566842, 0.9672858715, 0.9730985165, 0.9816912413],\n",
            "         [0.9996363521, 0.9988458157, 0.9661753178, 0.8662841320, 0.8726626039,\n",
            "          0.8564500809, 0.8648383617, 0.8429536819, 0.9329386950, 0.9919891357],\n",
            "         [0.9997655153, 0.9993889928, 0.9428212643, 0.7752907276, 0.7674431205,\n",
            "          0.7809264064, 0.8029863834, 0.8435199857, 0.9358794093, 0.9879133701]],\n",
            "\n",
            "        [[0.9934402108, 0.9962611794, 0.9514912367, 0.9468837380, 0.9851544499,\n",
            "          0.9996651411, 0.9973851442, 0.9990572333, 0.9971160889, 0.9977180958],\n",
            "         [0.9978412986, 0.9963513613, 0.9863007069, 0.9795095921, 0.9929236174,\n",
            "          0.9996365309, 0.9993817806, 0.9987290502, 0.9987843037, 0.9988278151],\n",
            "         [0.9983990788, 0.9990751743, 0.9990063906, 0.9991645813, 0.9993255138,\n",
            "          0.9996227622, 0.9993461967, 0.9994598031, 0.9999468327, 0.9995036721],\n",
            "         [0.9908753633, 0.9979854226, 0.9961692095, 0.9991065264, 0.9994331002,\n",
            "          0.9998522997, 0.9997713566, 0.9998175502, 0.9997655153, 0.9994288683],\n",
            "         [0.9944930673, 0.9863703251, 0.9821648002, 0.9946993589, 0.9954755306,\n",
            "          0.9984050393, 0.9982078075, 0.9950754642, 0.9966856837, 0.9982843399],\n",
            "         [0.9764466882, 0.9958602190, 0.9950649738, 0.9926950932, 0.9919831753,\n",
            "          0.9955679774, 0.9892586470, 0.9796320796, 0.9857976437, 0.9811935425],\n",
            "         [0.9835089445, 0.9834476113, 0.9891095757, 0.9847323298, 0.9768119454,\n",
            "          0.9836819172, 0.9727203846, 0.9536266327, 0.9733244777, 0.9716167450],\n",
            "         [0.9992194772, 0.9941241145, 0.9856662750, 0.9580675960, 0.9599643350,\n",
            "          0.9641193748, 0.9683575034, 0.9701649547, 0.9744250774, 0.9842992425],\n",
            "         [0.9997705817, 0.9991595149, 0.9579613805, 0.8667045236, 0.8807991743,\n",
            "          0.8572676182, 0.8682002425, 0.8448607922, 0.9403063655, 0.9943199158],\n",
            "         [0.9998505712, 0.9996179938, 0.9430357814, 0.7796483636, 0.7727801204,\n",
            "          0.7922239304, 0.8127251267, 0.8590978980, 0.9468754530, 0.9904629588]],\n",
            "\n",
            "        [[0.9939377904, 0.9956753850, 0.9515018463, 0.9484142661, 0.9868966341,\n",
            "          0.9996681213, 0.9963648915, 0.9986642003, 0.9962183833, 0.9968158007],\n",
            "         [0.9969292879, 0.9943178892, 0.9805022478, 0.9723050594, 0.9913174510,\n",
            "          0.9994708300, 0.9991242886, 0.9989384413, 0.9987360835, 0.9989239573],\n",
            "         [0.9983572364, 0.9988157749, 0.9987494349, 0.9990565777, 0.9992189407,\n",
            "          0.9995246530, 0.9988861084, 0.9992283583, 0.9999277592, 0.9993134737],\n",
            "         [0.9915726781, 0.9982704520, 0.9970357418, 0.9993391037, 0.9995092750,\n",
            "          0.9998524785, 0.9997534156, 0.9998129606, 0.9997306466, 0.9992836714],\n",
            "         [0.9939791560, 0.9848636985, 0.9855514169, 0.9951068163, 0.9951182604,\n",
            "          0.9985063076, 0.9983346462, 0.9957082272, 0.9971637726, 0.9986682534],\n",
            "         [0.9822070003, 0.9954537153, 0.9944937229, 0.9926626682, 0.9910195470,\n",
            "          0.9960412979, 0.9909721017, 0.9850809574, 0.9893397093, 0.9852141142],\n",
            "         [0.9782059789, 0.9870198369, 0.9886510372, 0.9855564833, 0.9778854847,\n",
            "          0.9854710698, 0.9743419290, 0.9540627599, 0.9692946672, 0.9647740126],\n",
            "         [0.9983800054, 0.9923784733, 0.9833357930, 0.9628840685, 0.9604159594,\n",
            "          0.9650263190, 0.9685491920, 0.9689110518, 0.9748058319, 0.9828196764],\n",
            "         [0.9996476769, 0.9988322854, 0.9581351876, 0.9007536769, 0.9031498432,\n",
            "          0.8841227293, 0.8900767565, 0.8634462357, 0.9374930859, 0.9928811193],\n",
            "         [0.9997701645, 0.9993455410, 0.9283224940, 0.7628139853, 0.7782739401,\n",
            "          0.7931990623, 0.8103347421, 0.8486329913, 0.9411118627, 0.9900966287]],\n",
            "\n",
            "        [[0.9886996150, 0.9921357632, 0.9317122698, 0.9249293208, 0.9772754312,\n",
            "          0.9989471436, 0.9936042428, 0.9967618585, 0.9922659993, 0.9926425219],\n",
            "         [0.9943336844, 0.9916442037, 0.9740735292, 0.9637247920, 0.9857149124,\n",
            "          0.9986568093, 0.9984654188, 0.9978739619, 0.9974237084, 0.9969046712],\n",
            "         [0.9968046546, 0.9978680015, 0.9978532791, 0.9983306527, 0.9984238744,\n",
            "          0.9990175962, 0.9981586933, 0.9984999895, 0.9998033047, 0.9983444214],\n",
            "         [0.9873387218, 0.9963557124, 0.9950093031, 0.9983837605, 0.9987218380,\n",
            "          0.9995163679, 0.9993827343, 0.9995098114, 0.9993050694, 0.9984868169],\n",
            "         [0.9909182787, 0.9828838706, 0.9776284695, 0.9912689924, 0.9913852215,\n",
            "          0.9973080754, 0.9971370697, 0.9936193824, 0.9952103496, 0.9974092841],\n",
            "         [0.9763713479, 0.9921162724, 0.9904854894, 0.9882385731, 0.9864388704,\n",
            "          0.9924129844, 0.9860039949, 0.9728175402, 0.9786826372, 0.9746884108],\n",
            "         [0.9763509035, 0.9808180332, 0.9854954481, 0.9783780575, 0.9684241414,\n",
            "          0.9756851196, 0.9628279805, 0.9353271127, 0.9560598731, 0.9561110735],\n",
            "         [0.9976164699, 0.9899095893, 0.9817895889, 0.9527451396, 0.9535812736,\n",
            "          0.9556286931, 0.9599406123, 0.9574981332, 0.9626882076, 0.9774460196],\n",
            "         [0.9991884232, 0.9977163672, 0.9575284123, 0.8722768426, 0.8819789886,\n",
            "          0.8630211353, 0.8671510220, 0.8399282694, 0.9244495034, 0.9894940853],\n",
            "         [0.9994268417, 0.9987154007, 0.9336600900, 0.7668706179, 0.7665738463,\n",
            "          0.7770813704, 0.7978881001, 0.8391659856, 0.9320313931, 0.9855045676]],\n",
            "\n",
            "        [[0.9867875576, 0.9920054674, 0.9286389947, 0.9205041528, 0.9755799770,\n",
            "          0.9989746809, 0.9941790104, 0.9970763326, 0.9929573536, 0.9935410619],\n",
            "         [0.9937595725, 0.9917998910, 0.9741908312, 0.9643305540, 0.9865158796,\n",
            "          0.9988420010, 0.9986501336, 0.9980076551, 0.9978704453, 0.9973363876],\n",
            "         [0.9951927662, 0.9967231750, 0.9964234829, 0.9970524907, 0.9974797368,\n",
            "          0.9985520840, 0.9979579449, 0.9986075163, 0.9998357296, 0.9986336827],\n",
            "         [0.9785013199, 0.9941632152, 0.9888069630, 0.9974043369, 0.9980805516,\n",
            "          0.9993216395, 0.9991143346, 0.9993621111, 0.9991191030, 0.9985114336],\n",
            "         [0.9858237505, 0.9798811674, 0.9583464861, 0.9862285256, 0.9895026088,\n",
            "          0.9961420894, 0.9948908687, 0.9880608320, 0.9916753769, 0.9959198833],\n",
            "         [0.9575797319, 0.9894353151, 0.9874973297, 0.9824509025, 0.9816867113,\n",
            "          0.9903017879, 0.9778724313, 0.9592200518, 0.9712992907, 0.9663019180],\n",
            "         [0.9674021602, 0.9707947969, 0.9795973301, 0.9666012526, 0.9567879438,\n",
            "          0.9657691121, 0.9556113482, 0.9287996292, 0.9532807469, 0.9511826634],\n",
            "         [0.9964627028, 0.9875553846, 0.9757345915, 0.9200397134, 0.9310356975,\n",
            "          0.9377043843, 0.9440947771, 0.9509473443, 0.9548566341, 0.9675741196],\n",
            "         [0.9986922145, 0.9969735742, 0.9488615394, 0.8069618344, 0.8319327831,\n",
            "          0.8086680174, 0.8212767839, 0.7974776030, 0.9000977278, 0.9844173789],\n",
            "         [0.9991030097, 0.9981310368, 0.9273961186, 0.7337011695, 0.7229151130,\n",
            "          0.7423428297, 0.7613369823, 0.8073902130, 0.9031573534, 0.9744073153]],\n",
            "\n",
            "        [[0.9943978786, 0.9961162210, 0.9541421533, 0.9508392811, 0.9885327816,\n",
            "          0.9997811913, 0.9977312088, 0.9992461801, 0.9972937703, 0.9978154302],\n",
            "         [0.9976561069, 0.9953204393, 0.9874139428, 0.9800879955, 0.9940804243,\n",
            "          0.9997231364, 0.9994557500, 0.9993400574, 0.9992592931, 0.9993865490],\n",
            "         [0.9978256226, 0.9985520840, 0.9981765747, 0.9985541105, 0.9988333583,\n",
            "          0.9994314909, 0.9990553260, 0.9995017648, 0.9999594092, 0.9996897578],\n",
            "         [0.9868257046, 0.9974358678, 0.9931452274, 0.9988663197, 0.9993591309,\n",
            "          0.9998410344, 0.9997126460, 0.9998039603, 0.9997465611, 0.9995587468],\n",
            "         [0.9917330146, 0.9849101305, 0.9803104401, 0.9920313358, 0.9951360226,\n",
            "          0.9985159636, 0.9971811771, 0.9917941689, 0.9951012731, 0.9977648258],\n",
            "         [0.9740956426, 0.9934832454, 0.9942176342, 0.9893450141, 0.9883635640,\n",
            "          0.9951095581, 0.9854774475, 0.9737477899, 0.9846023917, 0.9819573164],\n",
            "         [0.9763346910, 0.9814484715, 0.9873421788, 0.9779925942, 0.9704053402,\n",
            "          0.9815927148, 0.9685084224, 0.9588023424, 0.9739427567, 0.9715217948],\n",
            "         [0.9979141951, 0.9917639494, 0.9831110835, 0.9342422485, 0.9368640184,\n",
            "          0.9479575753, 0.9557497501, 0.9623504281, 0.9715760350, 0.9807370305],\n",
            "         [0.9995229244, 0.9985414147, 0.9575045109, 0.8389236927, 0.8418771029,\n",
            "          0.8291676044, 0.8383280635, 0.8238151073, 0.9258453846, 0.9920067191],\n",
            "         [0.9997128248, 0.9991501570, 0.9285172224, 0.7551262975, 0.7440651655,\n",
            "          0.7668951750, 0.7858073711, 0.8332266808, 0.9267103672, 0.9836067557]],\n",
            "\n",
            "        [[0.9883416295, 0.9924628139, 0.9326517582, 0.9263362885, 0.9781540632,\n",
            "          0.9991624355, 0.9943746924, 0.9973599911, 0.9934402108, 0.9940621853],\n",
            "         [0.9946993589, 0.9912965298, 0.9732152224, 0.9662321806, 0.9869859219,\n",
            "          0.9988813400, 0.9984730482, 0.9980196357, 0.9976798296, 0.9973824620],\n",
            "         [0.9963586330, 0.9975886941, 0.9973553419, 0.9978072047, 0.9981334209,\n",
            "          0.9988589883, 0.9980046749, 0.9986125231, 0.9998250604, 0.9984385371],\n",
            "         [0.9852302074, 0.9957637787, 0.9930744171, 0.9980286360, 0.9985084534,\n",
            "          0.9994943142, 0.9993302822, 0.9994676113, 0.9992686510, 0.9984200001],\n",
            "         [0.9896771312, 0.9773183465, 0.9735280275, 0.9893161058, 0.9907672405,\n",
            "          0.9970104694, 0.9964371920, 0.9911651611, 0.9938337803, 0.9971050620],\n",
            "         [0.9710190296, 0.9913361669, 0.9905128479, 0.9863808751, 0.9846323729,\n",
            "          0.9919696450, 0.9828617573, 0.9679795504, 0.9766171575, 0.9713518620],\n",
            "         [0.9700573683, 0.9787881374, 0.9837411046, 0.9742924571, 0.9623663425,\n",
            "          0.9723572135, 0.9578914642, 0.9335944057, 0.9567844868, 0.9534308314],\n",
            "         [0.9974057078, 0.9882986546, 0.9780525565, 0.9424228668, 0.9413490295,\n",
            "          0.9482165575, 0.9530404210, 0.9538924098, 0.9601287842, 0.9728794098],\n",
            "         [0.9991924763, 0.9976722002, 0.9477354884, 0.8542292118, 0.8561170101,\n",
            "          0.8370371461, 0.8462476730, 0.8203535080, 0.9169875383, 0.9885492325],\n",
            "         [0.9994350076, 0.9986737370, 0.9232122898, 0.7446549535, 0.7462691665,\n",
            "          0.7592256665, 0.7785683870, 0.8233249187, 0.9215686321, 0.9827018380]],\n",
            "\n",
            "        [[0.9884183407, 0.9915304184, 0.9296296239, 0.9259383082, 0.9785473347,\n",
            "          0.9991249442, 0.9933758974, 0.9974864125, 0.9928842187, 0.9941621423],\n",
            "         [0.9951310754, 0.9903994799, 0.9749739170, 0.9636011124, 0.9870885015,\n",
            "          0.9986960292, 0.9979306459, 0.9973952770, 0.9967839122, 0.9969857335],\n",
            "         [0.9970185161, 0.9980786443, 0.9980814457, 0.9984772205, 0.9986835122,\n",
            "          0.9991426468, 0.9982883930, 0.9986271262, 0.9997637272, 0.9981415272],\n",
            "         [0.9881061912, 0.9963057637, 0.9954388142, 0.9985691905, 0.9987705946,\n",
            "          0.9995990396, 0.9994204044, 0.9995160699, 0.9993445277, 0.9982258677],\n",
            "         [0.9913384914, 0.9769475460, 0.9797871709, 0.9919117689, 0.9914601445,\n",
            "          0.9972119927, 0.9970760345, 0.9934113026, 0.9954144359, 0.9975969791],\n",
            "         [0.9729991555, 0.9933422804, 0.9905363917, 0.9892143607, 0.9871317744,\n",
            "          0.9932015538, 0.9851575494, 0.9752354026, 0.9798979163, 0.9735915065],\n",
            "         [0.9709960222, 0.9810909629, 0.9830244780, 0.9801375866, 0.9674710035,\n",
            "          0.9769958854, 0.9611855745, 0.9341752529, 0.9565522671, 0.9543236494],\n",
            "         [0.9979602098, 0.9890717268, 0.9759685993, 0.9567824602, 0.9543359280,\n",
            "          0.9582894444, 0.9607281089, 0.9589858651, 0.9635444283, 0.9775891900],\n",
            "         [0.9993923903, 0.9979442954, 0.9405894876, 0.8785138726, 0.8822716475,\n",
            "          0.8618097901, 0.8679620028, 0.8408612013, 0.9294898510, 0.9915245771],\n",
            "         [0.9995719194, 0.9989454746, 0.9199221134, 0.7534859776, 0.7634203434,\n",
            "          0.7765796185, 0.7958547473, 0.8428214192, 0.9372262955, 0.9876944423]]])\n",
            "output= torch.Size([10]) tensor([390.2462158203, 393.9235839844, 381.8196105957, 379.6242980957,\n",
            "        400.2731933594, 382.3416748047, 399.7404174805, 387.4907226562,\n",
            "        390.1951293945, 398.5203552246])\n"
          ]
        }
      ],
      "source": [
        "#printing input and output\n",
        "Flat_output=flattening(pooling_output,10)\n",
        "print('input=',pooling_output)\n",
        "print('output=',Flat_output.shape,Flat_output)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ES-M5hICPzeC"
      },
      "source": [
        "**QUESTION 6**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<Font size=2> **Softmax function**\\\n",
        "e^x/sum(e^x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "id": "paUe0wu_NBKq"
      },
      "outputs": [],
      "source": [
        "#softmax function\n",
        "def softmax(output):\n",
        "\n",
        "  for i in range(output.shape[0]):\n",
        "    output[i]=torch.exp(output[i])\n",
        "\n",
        "\n",
        "  output=output/output.sum()\n",
        "  \n",
        "  return output"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<Font size=2>**MULTI LAYER PERCEPTRON FUNCTION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "id": "cdGJ0FztP57i"
      },
      "outputs": [],
      "source": [
        "def mlp(inp_vector,number_of_hidden_layers,hidden_layer_size,non_linear_function,output_layer_size,kernel_list=None):\n",
        "\n",
        "  inp_vector_length=inp_vector.shape[0]\n",
        "\n",
        "   #randomly initializing weight matrix if it is not given\n",
        "  if kernel_list==None:\n",
        "    inp_weight=torch.rand([inp_vector_length,hidden_layer_size])\n",
        "    output_weight=torch.rand([hidden_layer_size,output_layer_size])\n",
        "    weight_matrix=torch.rand([number_of_hidden_layers-1,hidden_layer_size,hidden_layer_size])\n",
        "\n",
        "\n",
        "  #assigning weights given in kernel_list to variables\n",
        "  else:\n",
        "    inp_weight=kernel_list[0]\n",
        "    output_weight=kernel_list[1]\n",
        "    weight_matrix=kernel_list[2]\n",
        "\n",
        "\n",
        "  #for input layer\n",
        "  output=non_linear_function(inp_weight.T@inp_vector)\n",
        "\n",
        "  #loop for hidden layers\n",
        "  for i in range(number_of_hidden_layers-1):\n",
        "    output=non_linear_function(weight_matrix[i].T@output)\n",
        "\n",
        "  #for output layer\n",
        "  output=(output_weight.T@output)\n",
        "\n",
        "  \n",
        "  return output,softmax(output)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<Font size=2>**Printing outputs**\\\n",
        "prints mlp input, output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxyXx8GWMmoE",
        "outputId": "4ab6536a-53b9-4035-93e2-d3d1f4f3fd45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input= tensor([0.9756155610, 0.9848089814, 0.9545490146, 0.9490607381, 1.0006829500,\n",
            "        0.9558541775, 0.9993510246, 0.9687268138, 0.9754878283, 0.9963008761])\n",
            "output without softmax= tensor([47.4512710571, 10.6163473129])\n",
            "output with softmax= tensor([0.8171726465, 0.1828273237])\n"
          ]
        }
      ],
      "source": [
        "#printing input and outputs\n",
        "inp=Flat_output/400\n",
        "mlp_output=mlp(inp,1,5,sigmoid,2)\n",
        "\n",
        "print('input=',inp)\n",
        "\n",
        "print('output without softmax=',mlp_output[0])\n",
        "print('output with softmax=',mlp_output[1])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**QUESTION 7**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iLEdXjeOUFvi"
      },
      "source": [
        "<font size=2>**FEED FORWARD PATH**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "id": "8nwQJA75UJhz"
      },
      "outputs": [],
      "source": [
        "def feed_forward_path(inp,kernel_list=None):\n",
        "\n",
        "  #setting kernels to none if kernel_list is not given\n",
        "  if kernel_list==None:\n",
        "    kernel_list=[None,None,None,None]\n",
        "\n",
        "\n",
        "  #Convolution layer with 16 kernels of size 3  3 spatial dimensions and sigmoid activation.\n",
        "  output=convolution_layer_function(input=inp,number_of_filters=16,kernel_dimensions=torch.tensor([3,3]),non_linear_function=sigmoid,kernel=kernel_list[0])\n",
        "  \n",
        "\n",
        "  # Max pooling layer of size 2  2 with a stride of 2 along each dimension.\n",
        "  output=pooling_layer_function(input=output,stride=torch.tensor([2,2]),pooling_func=max_pool,kernel_size=torch.tensor([2,2]))\n",
        "\n",
        "\n",
        "  #Convolution layer with 8 kernels of spatial size 3  3 and sigmoid activation.\n",
        "  output=convolution_layer_function(input=output,number_of_filters=8,kernel_dimensions=torch.tensor([3,3]),non_linear_function=sigmoid,kernel=kernel_list[1])\n",
        "\n",
        "\n",
        "  #Max pooling layer of size 2  2 with a stride of 2 along each dimension\n",
        "  output=pooling_layer_function(input=output,stride=torch.tensor([2,2]),pooling_func=max_pool,kernel_size=torch.tensor([2,2]))\n",
        "\n",
        "\n",
        "  #A Global Average Pooling (GAP) layer.\n",
        "  output=pooling_layer_function(input=output)\n",
        "\n",
        "  \n",
        "  output=flattening(output,output.size(0),weight_matrix=kernel_list[2])\n",
        "  mlp_input=output\n",
        "\n",
        "  #An MLP with one hidden layer (size same as input) that accepts as input the previous layers output and maps it to 10 output nodes. Use sigmoid activation for the MLP (softmax in the o/p layer).\n",
        "  output=mlp(inp_vector=output,number_of_hidden_layers=1,hidden_layer_size=output.shape[0],non_linear_function=sigmoid,output_layer_size=10,kernel_list=kernel_list[3])\n",
        "\n",
        "\n",
        "  return output[0],output[1],mlp_input"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<Font size=2>**Printing outputs**\\\n",
        "prints feed forward input(image), output(vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input image=\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAchElEQVR4nO2da4yc53Xf/2dmdvbOXS2XXC4vNmXdHNlwJJcQXMQI3AQJFDeA7MAVbCeqWhhhUMRADaQfBBeoXaAfnKK24Q+NC7oSohSuLvUlVhohiSMIUF0kMilVliipNiWKFEktd8nl3q9zOf0wQ5RUnv/Z5ezu7NrP/wcsduY587zv8z7ve+adef5zzjF3hxDiF5/Cdg9ACNEe5OxCZIKcXYhMkLMLkQlydiEyQc4uRCaUNtLZzO4F8A0ARQD/1d2/Er1+cGDA943sI9tqaQTB2FrZ3lp7IxttdV+B6umBkY4josUxRvuK53gLTgAhmqudgoXnevO4MPYOpqank5PfsrObWRHAfwbwGwDOAzhuZk+5+2usz76RfXjkT/6EbY/uq1gs3nCfyFZo8UJk4ygUWvuAVK/XqS36/UMrxx32oRago5A+ZgAolfjl08o4IurBfNQCWx1kjgMPa3WMFp2zOrdtprP/zoMPUNtGPsbfA+ANdz/t7qsAHgdw3wa2J4TYQjbi7AcAnLvm+flmmxBiB7LlC3RmdtTMTpjZiemZ6a3enRCCsBFnvwDg0DXPDzbbrsPdj7n7EXc/MjgwuIHdCSE2wkac/TiA28zsZjMrA/g0gKc2Z1hCiM2m5dV4d6+a2ecB/DUa0tsj7v7qGr1QrVaTllZXtBmtrsazFXeAr5DX6zXap1bjK+7Ranw0H5GNHXfUJzrmYouKRyur8ZECEUZnBovnxQK5xFvcV8sqSYHb6rX09RNJik5X93mfDens7v40gKc3sg0hRHvQL+iEyAQ5uxCZIGcXIhPk7EJkgpxdiEzY0Gr8jeLOpYtW5I5WgzuiOIdW5KRIuiqVWpOaWpXe2FiioJVwX5HkFZiYrNiqdFUIpKtwPshxR+OIJNEakckAwAOZNZL66HFHETItxOrozi5EJsjZhcgEObsQmSBnFyIT5OxCZEJbV+PNWgvU6OjoSLZHq+DR25iV+DJnuVimtmI9vdHFhUXaZ2pqitpmZ7ltemqS2paW+P7YKnNvby/ts2vXLmrr6+W2/v4Batu7dyTZ3t3dQ/tUVivUVg/SOlmU4I0saceZp6J0YZEtWKkPxt8KxWL6WoxyBurOLkQmyNmFyAQ5uxCZIGcXIhPk7EJkgpxdiExoq/QW8fbbb1PbhQv/IGktAGB5ZZn26Sx3UltXB5fXvLJCbUuLs8n2mdnLtM/syhy1rS5xqakS2KK8duVy+tg8CO5YXuHHvLDEbb19XJYb3ZcuIfCBD3yA9rn77n9EbQODg9RGq76AS2UsF+JatihYp1QKpOBAeosCb254X4GkqDu7EJkgZxciE+TsQmSCnF2ITJCzC5EJcnYhMmFD0puZnQEwB6AGoOruR1rdVpQTbIVIQ2fPcLluefEKtZWdS2XlIo9cWq2kJZn55UDGKXIJcGGOy2sT7/AxRtLQwQP7k+179uyhfTyQrlYqXN6sLfBzNn96Idn+ymsnaZ+/P/5javvUp/4Ztd16663UVqnwOWZE0ZSR9FYsBP0KfK5YXruWymsF2ttm6Oz/xD3wHiHEjkAf44XIhI06uwP4GzN7wcyObsaAhBBbw0Y/xn/U3S+Y2V4APzSz/+vuz137guabwFEAGNm7d4O7E0K0yobu7O5+ofl/AsD3AdyTeM0xdz/i7kcGB3gaIyHE1tKys5tZr5n1X30M4DcB8KVWIcS2spGP8SMAvt+UAEoA/ru7/1XcxWgZokg+uf3225PtFSKFAcDyEk/muDh/ltomJ7jt7OnTyfbTp8don5Uql97QyaPvdu3iSSWLRX7aBgb70gbjkuLyCt9Xpc6lq4V5Lst1lNLHViLtAPDGW6eo7YknH6e2T37id6jt/Xe8P9leDxJHRslPY1orbcUSqoZ7YlJ1EPXWsrO7+2kAv9xqfyFEe5H0JkQmyNmFyAQ5uxCZIGcXIhPk7EJkwo6p9RZF6xSJFFLu4XXD+oNkiD58mNr27UsnlQSA4eE3ku2ljuO0z8TEJWqLEj0ODPDabJXVVWorsIitQGrqIHXDAGBXTxe1zS8tURtLBhqVPCt2cJnyzIXz1PYXT/8FtXX3difbDx08RPuEMlmJy2SlIFqulbtqFAnKklRGY9edXYhMkLMLkQlydiEyQc4uRCbI2YXIhPaWf3LA2AJjsPLI4guikkYOHsBhwVtcdy9fBb/ltg8l2/v6Bmmfl156ntoujqXLWgFANQryWeYBKAsL6dxvEb096RVrIA4K6QwCOKZm0+OoF/glVwnKWlVq/Hy++tPXqO2J76QDaB743Qdpn0MH+Ep9wfiKe5SDrljgq+Rs1b2VslARurMLkQlydiEyQc4uRCbI2YXIBDm7EJkgZxciE9orvQWBMPVAemPlcaJAgeh9rBhpb9EmSb+9e/bRLiMjo9S2vMRlspnpGWqLyj+xfGbxXHEKRS6v+RIPyKmTiJe687HXqjxPHjxIrhYE8pw8mc6B+ud//n3a54HP/nNqGxocorbVVT7+jlJrJaU2s4/u7EJkgpxdiEyQswuRCXJ2ITJBzi5EJsjZhciENaU3M3sEwG8DmHD3DzbbhgA8AeAwgDMA7nd3Xm/p+u0l21vJt9U6/D0uVqjSxlIQyTU4wKWaiW6eQ8+DZG1RJFovidqL+szM8Lx758cvU9v8Eo++K5AyXx2kHQD6+gKZL8hRWA1sTM578YUXaZ/uMj8vn7n/09Q2MMDzHkZyaZHkrgvzyZHzudEcdH8K4N53tT0E4Bl3vw3AM83nQogdzJrO3qy3fuVdzfcBeLT5+FEAn9jcYQkhNptWv7OPuPvV0qUX0ajoKoTYwWx4gc4bX7bpF0wzO2pmJ8zsxHTwE1AhxNbSqrOPm9koADT/T7AXuvsxdz/i7kcGBwda3J0QYqO06uxPAbiaxOtBAD/YnOEIIbaK9UhvjwH4GIBhMzsP4EsAvgLgSTP7HICzAO7f6EBaicpikVUAYMbluijyCvUgmojsLnrHXFnhiRIXF7l0xSL9gFhGY7YoEeXsHJfeyp28JNOh4T3UxmaxWuHzgUBiXVzmpbJmFhapjZVrqgSn+dlnn6W2KDLvdz/7GWobGrqJb5Mk2mSSHBD4S+BGazq7u7Mj+PW1+gohdg76BZ0QmSBnFyIT5OxCZIKcXYhMkLMLkQntTTgZEMlJLJLHgminyFQocomngEDyQloKGRt/h/Z5+eRL1DY7zSPK6oH0FkUBthJV2N/XT20DxTIfR5AEktXhW0YgewaJQC2Yj2Jg6yynx++d/NIvBckh/+7431Hb3PI8tf3LB/8Fte0fTSclra1ymdLJXHmgvenOLkQmyNmFyAQ5uxCZIGcXIhPk7EJkgpxdiEzYMdJbK0QygzmXT1DjtlIHn5J3LpxJtp84/iPaZ2ZqnNqqVS6t1KqtJZxkslycvJDPx9LSErXNzMxRW4kkliwTKayxPZ7cJDrXlQqPiOsop8exusojDqtBftOu7m5qO378eWq7ODZGbb/32d9Ltn/knnv4QGjE58YSTgohfgGQswuRCXJ2ITJBzi5EJsjZhciEHbMav+klnoJcXMUiP+zxsXPU9uO/fy7Zfv7cadqnGqwUR2n3KkGus84gL1yF5Hibn+dBGgMDg9S2ssrHMTXFK36x1f+eHl5aKVqND8QEkPgkAMDCQjq/3mqFH1eU7y66PXZ1dVHb2NhFajt27Fiy/exbb9E+//S3Pp5sr9ejQC4hRBbI2YXIBDm7EJkgZxciE+TsQmSCnF2ITFhP+adHAPw2gAl3/2Cz7csAfh/ApebLvujuT2/VIKMgDkYQK4L5OZ777cUX/je1vfXWT5Pt05PvLl9/DTU+9n3707nHAGB8/AzfZjAfAwPp4pkrK1xOWlrk5ZOioJAoOKVEShdF5aT6+3dR28wsl/mWlvj4Sx3p8k8dnVwmK3VwLW9mOpAbC+l9AUC5xANo5kj5rccee4z2uXzpUrJ9cnKS9lnPnf1PAdybaP+6u9/V/NsyRxdCbA5rOru7PwcguHUJIX4e2Mh39s+b2ctm9oiZ8RKVQogdQavO/k0AtwC4C8AYgK+yF5rZUTM7YWYnpqf5zyGFEFtLS87u7uPuXnP3OoBvAaApNdz9mLsfcfcjg4PpxSMhxNbTkrOb2bXLyJ8EcHJzhiOE2CrWI709BuBjAIbN7DyALwH4mJndhUZs2RkAf7DeHbIyRJG8ViQyjgX6WimQhd5462fU9vb5U9Q2ReSfggXTWOeyUH8XP+bB/j5qO3v+bWq7aSj96ck8iPKa41+vegcHqa1/gMtJRkLR5uZ53rrFBZ7vbmj3Hr6v4JZ1ZSq9tuyBpFiIIiaDUMXVlSCvXZWXvSp3pOVICw7sL//6r5LtM7P8XK7p7O7+mUTzw2v1E0LsLPQLOiEyQc4uRCbI2YXIBDm7EJkgZxciE9qacNLdUaulJaBWIttKQZ9qjUsdV4LIoHptlW9zNR05dlP/XtrHOvn76coyl5o6g8irYvAWXSql52T/6Ajtc+aNN6mtHpyW7v5+ajNyH+np5pFtczPT1DZ1hZ+z9xw+TG2lUjoS7ezZs7RPFCE4OsojFaeChJmLwTbr9XSSUA8m3yzIsknQnV2ITJCzC5EJcnYhMkHOLkQmyNmFyAQ5uxCZ0PZab5tZ043JeABgQXRSuZMnBhzs45Fc1T3phDyTl3kdta4enthwcSUtuQBAbZVHUO3q4/XSukppSWagr5f22beXR5RNLfBx9PfwyDxWW64j0A1ved9Bars8yRM9Xhx7h9qGdg8n2/ft20f7jI2NUVt0/R48sJ/aZmbTSSUBYH5uIdleDbJ9lsh5jiRs3dmFyAQ5uxCZIGcXIhPk7EJkgpxdiExoeyBMtZJegS6W+FDYqnslyusVrPp2lXkJono1CILYM5RsX5znNTQmZ3kOuqUCX43vL1MTSKwLAKBWTQfyrC7zcawspVeDAWB5gc/H6hK3LZDV56LxFeb9+3mwTmegoJw5ly6FBADT09PJ9oMH+cr/7t27qe3cuXPUdvkyH8fBgweora83rZRMjPPt0Xx3QXI93dmFyAQ5uxCZIGcXIhPk7EJkgpxdiEyQswuRCesp/3QIwJ8BGEGj3NMxd/+GmQ0BeALAYTRKQN3v7jxaoYkT2ahS5TIUyI/7PQhKqDvP0dW5i+dBK1kQJFNOT9cto7xi9dIZLg9eCoI7fIDLg73B+Gem0zLgTUGQxs3v5XnVui/xAI6pKS4NTVwYT7b3d72P76vEj3lyieeg6wzSsS0spstNLc7zfHH79/O5WljgxUnPX+ABOT87xfP87SbBOrtuGqR9lpfS0luBlEoD1ndnrwL4I3e/E8BHAPyhmd0J4CEAz7j7bQCeaT4XQuxQ1nR2dx9z9xebj+cAvA7gAID7ADzafNmjAD6xRWMUQmwCN/Sd3cwOA7gbwPMARtz9auDvRTQ+5gshdijrdnYz6wPwXQBfcPfrvsh5ow5zMluEmR01sxNmdmImyKsthNha1uXsZtaBhqN/292/12weN7PRpn0UwESqr7sfc/cj7n5kYIAvbgghtpY1nd0aeW4eBvC6u3/tGtNTAB5sPn4QwA82f3hCiM1iPVFvvwLgAQCvmNlLzbYvAvgKgCfN7HMAzgK4fz07rJPccJuZm665I2oaGuYRSLfc8iFqmxs7nWzfcxPPW7d3hkeUTU7z8LX5VT4fXX1cHix1pHPeXZlOS1AAsGeYS4cHDnPbwALPrze8Ny0PBqkBUSrznILDwzzfXXcPz8m3Wkvv0ApcoorKcl28eJHaasE119PHS2Utk0jQjiAStKsnfc0VCvz+vaazu/uPALCr8tfX6i+E2BnoF3RCZIKcXYhMkLMLkQlydiEyQc4uRCa0vfwTK09TDKJ1eEmbQMcB354H73E33/5hajtDQvbeevM12qe3k+/r4D5edunyLJfsllaipILp416t8T7LEzyyrauHj9+COe7oSktvNSKFAcB4UEarr5/La3tHuPRZIfubmeMJOMeDRI8dJS43lspcSi2VeQZRdu1XiCQHACsr6WSfkYStO7sQmSBnFyIT5OxCZIKcXYhMkLMLkQlydiEyYcdIbx6EQ3G5jg+/FNiqQY24gvHopPe8Py3LVetcchkLZLmz55MpAAAAl69wOayjxKPeykTiieeX1A0D0N/HpaZqhcs801PpY4vkus4uLk/t6ufnc3AgkG1JFNjkJJf5ZmZ41NtSEI3IkqkCQLHMx8iux85OnoCznyQdNeP3b93ZhcgEObsQmSBnFyIT5OxCZIKcXYhMaPtqfLQqvMl7opZigS+bVoPhFXrSedDu+ODdtE9nEJgwt8RVgVJ3uowTAIxPctv0AllJLvBTvbDIg0KuBOm/+3t7qa1MajIZ+HwUC+ngDgDo7Q4CSYJzvTDPAop4n/4BrsjYIg9OmZnnCsrMVJBGnVwjHgQvLc2n1YRqZZX20Z1diEyQswuRCXJ2ITJBzi5EJsjZhcgEObsQmbCm9GZmhwD8GRolmR3AMXf/hpl9GcDvA7iasOuL7v50qwPheeY4UY6u6iqXtYrBYVeLQaCDp8sT9XTywJSR995KbbPTk9TWz+NPcGAoHQQBAKffSQegXApy2h06dAe1lYJyQlcu81xtA71pqWzfHl7cs6+Ln5fuTm5bXuLSYRcpoWRBDrqpOT5XCKTD3l5+0oolHghTr6Wvq1JQoqqHlLwqFvk5WY/OXgXwR+7+opn1A3jBzH7YtH3d3f/TOrYhhNhm1lPrbQzAWPPxnJm9DoBXRhRC7Ehu6Du7mR0GcDeA55tNnzezl83sETPj5T6FENvOup3dzPoAfBfAF9x9FsA3AdwC4C407vxfJf2OmtkJMzsxHfz0UgixtazL2c2sAw1H/7a7fw8A3H3c3WvuXgfwLQD3pPq6+zF3P+LuRwYH+OKMEGJrWdPZrbFM/jCA1939a9e0j17zsk8COLn5wxNCbBbrWY3/FQAPAHjFzF5qtn0RwGfM7C405LgzAP5gPTssECknkt6YrVZPSxYAUCNyBgCgGOTpCnJ4maWlkFoQ2dY3NExtt/3SndT26vHL1Dbxzjt8m/vSSyd33Hoz7TMf5FVbWOT52EqDPDqsi0S9lYLz3NXJpau+IBfe0CCXIqvkOhhZ5hF2U7M8P934BD8vl65wOW8luBxXltMS8rJxaXmeRLdVgut+PavxPwKQOkMta+pCiPajX9AJkQlydiEyQc4uRCbI2YXIBDm7EJnQ1oST7rzUzWYnooy2trzCyx3Vlrh0wcrxFAI5qRLYevZyOewOnsMSq9X/RW1j595Mtg8RKQwAusrpCCoAmB7nkXmdQURcX1daKqsFkYqTV3gizflFnnCyv59LgH196aSY/QP8mLt7+fb6+9JJRwFgaJhfV1eCklLsl6WTU3w+Zufm0gbnMqru7EJkgpxdiEyQswuRCXJ2ITJBzi5EJsjZhciEtkpv1UoFFy9eTNqWlrg0wRJL7t69m/ZZDqKa6kENrY4OLvGUO9KJJaPIsO6gHtr+/Yeobdd7fonaPhRE7Q2RSLQ3T71O+3T28uSchw+MUNv0HI8O6+5Kz6MV0vIlANTBZc+lVS7ZXZzkNdaKMywSjYuztSofx+oqv66WA1mxUuHbLFp6/ncHkX7DPen5vXCZnxPd2YXIBDm7EJkgZxciE+TsQmSCnF2ITJCzC5EJbZXe6l7HykpaumCJKAEebXZpIl3XDAD6gkioW2/n9deKwTiqRP5h7UAcEddV4nJMlIBz1+hhattfSMuDpYE9tM/bZ39KbTMzJLoKQLnMa9ytrKTlyF0D/Lx0d/NItL5AupqZ59Fm9WT6RMCKPApwtcD3tbzCZcqlhahGHGd4KC0h776J113p7U77xAtneEJM3dmFyAQ5uxCZIGcXIhPk7EJkgpxdiExYczXezLoAPAegs/n677j7l8zsZgCPA9gN4AUAD7h7uibN/99aS+WfWCBMb5APrBistp48ycvS9QWBK6N700Eh3UHZIn5UwOpqMF1Bx3KRr4IPjRxIti8s8gCJXfM8kMQ6+RxPXZmitjrS83/p8jTtsxiMsbe3m9rKHfwyHhgkxUQLvM9ykQfJ9PUOUdvI8CC1mfMT2tufLl81u8DLSZ16eyzZvhJcU+u5s68A+DV3/2U0yjPfa2YfAfDHAL7u7rcCmALwuXVsSwixTazp7N7g6ltuR/PPAfwagO802x8F8ImtGKAQYnNYb332YrOC6wSAHwJ4E8C0u1/9hcF5AOnPj0KIHcG6nN3da+5+F4CDAO4B8P717sDMjprZCTM7MT/Pv5MJIbaWG1qNd/dpAM8C+McABs3s6irHQQAXSJ9j7n7E3Y/0BQtqQoitZU1nN7M9ZjbYfNwN4DcAvI6G03+q+bIHAfxgi8YohNgE1hMIMwrgUTMrovHm8KS7/08zew3A42b2HwD8HwAPr7Uh9zqVm6LyT6xPdzeXYyIpj5WgivYF8Dx5fT1croskwNVKIL0VeL9KnR9bqZiWAQ/cfAft07WLB6ecOXWK2mA8n1yhyMbIg0wmLo3z7QW3pd4efh2wQJhSiculHcFxFUtc9qwEAVGXLl2itnNjaZsbP+iF5fS1U6tzP1rT2d39ZQD/oPKYu59G4/u7EOLnAP2CTohMkLMLkQlydiEyQc4uRCbI2YXIBIskr03fmdklAGebT4cB8IRZ7UPjuB6N43p+3sbxXndPJhxsq7Nft2OzE+5+ZFt2rnFoHBmOQx/jhcgEObsQmbCdzn5sG/d9LRrH9Wgc1/MLM45t+84uhGgv+hgvRCZsi7Ob2b1m9lMze8PMHtqOMTTHccbMXjGzl8zsRBv3+4iZTZjZyWvahszsh2Z2qvmf1/7Z2nF82cwuNOfkJTP7eBvGccjMnjWz18zsVTP71832ts5JMI62zomZdZnZj83sJ81x/Ptm+81m9nzTb54ws/INbdjd2/oHoIhGWqv3ASgD+AmAO9s9juZYzgAY3ob9/iqADwM4eU3bfwTwUPPxQwD+eJvG8WUA/6bN8zEK4MPNx/0AfgbgznbPSTCOts4JGrmF+5qPOwA8D+AjAJ4E8Olm+38B8K9uZLvbcWe/B8Ab7n7aG6mnHwdw3zaMY9tw9+cAXHlX831oJO4E2pTAk4yj7bj7mLu/2Hw8h0ZylANo85wE42gr3mDTk7xuh7MfAHDumufbmazSAfyNmb1gZke3aQxXGXH3q8nALwJIJ6lvD583s5ebH/O3/OvEtZjZYTTyJzyPbZyTd40DaPOcbEWS19wX6D7q7h8G8FsA/tDMfnW7BwQ03tnReCPaDr4J4BY0agSMAfhqu3ZsZn0AvgvgC+5+XeWKds5JYhxtnxPfQJJXxnY4+wUAh655TpNVbjXufqH5fwLA97G9mXfGzWwUAJr/efH5LcTdx5sXWh3At9CmOTGzDjQc7Nvu/r1mc9vnJDWO7ZqT5r6ncYNJXhnb4ezHAdzWXFksA/g0gKfaPQgz6zWz/quPAfwmAF4Xaut5Co3EncA2JvC86lxNPok2zIk1EgY+DOB1d//aNaa2zgkbR7vnZMuSvLZrhfFdq40fR2Ol800A/3abxvA+NJSAnwB4tZ3jAPAYGh8HK2h89/ocGjXzngFwCsDfAhjapnH8NwCvAHgZDWcbbcM4PorGR/SXAbzU/Pt4u+ckGEdb5wTAh9BI4voyGm8s/+6aa/bHAN4A8D8AdN7IdvULOiEyIfcFOiGyQc4uRCbI2YXIBDm7EJkgZxciE+TsQmSCnF2ITJCzC5EJ/w9+q65Hc26+4gAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output after softmax= tensor([0.0990286916, 0.0233638752, 0.4987521470, 0.1527588814, 0.0459361933,\n",
            "        0.0326926410, 0.0380975790, 0.0617306083, 0.0372269340, 0.0104125226]) torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "#testing feed forward function\n",
        "inp =  image_list[2][2]\n",
        "\n",
        "#printing input image\n",
        "print('input image=')\n",
        "plt.imshow(inp.permute(1,2,0))\n",
        "plt.show()\n",
        "\n",
        "#print feed_forward output\n",
        "ff_out=feed_forward_path(inp)\n",
        "print('output after softmax=',ff_out[1],ff_out[1].shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**QUESTION 8a:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "class 0 output= tensor([0.2723104358, 0.0468355641, 0.0828735903, 0.0735564083, 0.1768710315,\n",
            "        0.0704051480, 0.2090381384, 0.0205016211, 0.0323970057, 0.0152109871])\n",
            "class 1 output= tensor([0.2723103762, 0.0468355678, 0.0828736201, 0.0735564381, 0.1768710464,\n",
            "        0.0704051480, 0.2090381533, 0.0205016304, 0.0323970132, 0.0152109927])\n",
            "class 2 output= tensor([0.2723103762, 0.0468355678, 0.0828736201, 0.0735564381, 0.1768710464,\n",
            "        0.0704051480, 0.2090381533, 0.0205016304, 0.0323970132, 0.0152109927])\n",
            "class 3 output= tensor([0.2723103464, 0.0468355604, 0.0828736126, 0.0735564977, 0.1768709868,\n",
            "        0.0704051405, 0.2090381384, 0.0205016416, 0.0323970169, 0.0152110057])\n",
            "class 4 output= tensor([0.2723104358, 0.0468355641, 0.0828736126, 0.0735564828, 0.1768710166,\n",
            "        0.0704051554, 0.2090381384, 0.0205016378, 0.0323970132, 0.0152110010])\n",
            "class 5 output= tensor([0.2723103464, 0.0468355604, 0.0828736126, 0.0735564977, 0.1768710315,\n",
            "        0.0704051554, 0.2090381384, 0.0205016416, 0.0323970169, 0.0152110057])\n",
            "class 6 output= tensor([0.2723104060, 0.0468355604, 0.0828736275, 0.0735564455, 0.1768710613,\n",
            "        0.0704051554, 0.2090381235, 0.0205016322, 0.0323970169, 0.0152109936])\n",
            "class 7 output= tensor([0.2723104358, 0.0468355641, 0.0828736126, 0.0735564455, 0.1768710315,\n",
            "        0.0704051480, 0.2090381384, 0.0205016304, 0.0323970169, 0.0152109917])\n",
            "class 8 output= tensor([0.2723104358, 0.0468355641, 0.0828735903, 0.0735564157, 0.1768710315,\n",
            "        0.0704051480, 0.2090381384, 0.0205016211, 0.0323970132, 0.0152109843])\n",
            "class 9 output= tensor([0.2723104358, 0.0468355753, 0.0828736126, 0.0735564157, 0.1768710315,\n",
            "        0.0704051629, 0.2090381384, 0.0205016211, 0.0323970132, 0.0152109843])\n"
          ]
        }
      ],
      "source": [
        "#creating a kernel_list which contains all randomly initialized required for convolution_layer_function,flattening,mlp functions\n",
        "kernel_list=[]\n",
        "\n",
        "#appending kernel required for 1st convoltion_layer_function\n",
        "kernel_list.append(torch.rand([16,3,3,3])/100)\n",
        "\n",
        "#appending kernel required for 2nd convoltion_layer_function\n",
        "kernel_list.append(torch.rand([8,16,3,3])/100)\n",
        "\n",
        "#appending weight matrix required for flattening function\n",
        "kernel_list.append(torch.rand([8,8]))\n",
        "\n",
        "#creating weight_matrix list containing required weights for mlp function\n",
        "weight_matrix=[]\n",
        "weight_matrix.append(torch.rand([8,5]))\n",
        "weight_matrix.append(torch.rand([5,10]))\n",
        "weight_matrix.append(torch.rand([4,5,5]))\n",
        "\n",
        "#appending weight matrix required for mlp function\n",
        "kernel_list.append(weight_matrix)\n",
        "\n",
        "#selecting an image from each of the 10 classes and displaying the output vector for each case.\n",
        "for i in range(10):\n",
        "    print('class',i,'output=',feed_forward_path(image_list[i][0],kernel_list)[1])\n",
        "    "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Analysis for 8a**\\\n",
        "**Trend observed:** We observe that all images(one from each class), same(approximately) output vector.\\\n",
        "**Reason:** Our model is not trained. So, it outputs same vector for evry image."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**QUESTION 8b**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<Font size=2> **Loading 3 images from each class.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Storing 3 images from each class in pca_input. Storing class number of corresponding images in pca_classno\n",
        "pca_input=[]\n",
        "pca_classno=np.zeros([30,1])\n",
        "k=0\n",
        "for classno in range(10):\n",
        "    for img in range(3):\n",
        "        pca_input.append((feed_forward_path(image_list[classno][img],kernel_list)[2]).numpy())\n",
        "        pca_classno[k]=classno\n",
        "        k=k+1\n",
        "\n",
        "pca_input=np.array(pca_input)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "pca=PCA(n_components=2)\n",
        "\n",
        "#reducing dimensions of stored flattening layer output to 2D so that we can visualizein 2D\n",
        "reduced_dim=pca.fit_transform(pca_input)\n",
        "\n",
        "\n",
        "plt.scatter(reduced_dim[:,0],reduced_dim[:,1],c=pca_classno,cmap=plt.get_cmap('rainbow',10))\n",
        "plt.xlabel('principal component 1')\n",
        "plt.ylabel('principal component 2')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Analysis for 8b**\\\n",
        "Randomly initialized network doesn't show any discriminability.\\\n",
        "Here, after performing PCA, we can see that images of same class are not clustered together. Since our model is not trained and randomly initialized, same class images are not clustered together"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
